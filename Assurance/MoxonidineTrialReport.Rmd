---
title: "Moxonidine Trial"
header-includes:
- \usepackage{caption}
always_allow_html: true
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(RColorBrewer)
```

## Introduction

This report outlines a clinical trial which can be found here: <https://pubmed.ncbi.nlm.nih.gov/17968979/>. The trial compared the drug moxonidine against a placebo in a double-blind trial. We will discuss the trial; how the sample size was calculated, how the trial was conducted and the results of the trial. We will also retrospectively compute assurance for this trial, both before and during (in the interim analysis). Using assurance would have helped the study team in this trial as they would have been able to give distributions for their beliefs about the control and also for the effect of the experimental treatment. If they were unsure of their beliefs about either then this could be modelled by the distributions and the assurance calculations would reflect this. Therefore everyone involved in the trial would be more informed, from the sponsors to the study team. 


## Background

Myocardial ischaemia is the leading cause of morbidity and mortality after surgery on patients with coronary artery disease. Patients were randomly assigned the drug moxonidine or a placebo (with ratio 1:1) to be taken the morning before surgery and on days 1 to 4 after surgery. Study medication was administered by a member of the team blinded to treatment allocation. The endpoint of the trial was measuring the difference in levels of cTnI before surgery and 7 days post surgery, an increase of 2$\mu$g/l of cTnI was interpreted as being clinically significant in increasing the probability of myocardial ischaemia. 


## Trial Design

Based on an incidence of myocardial ischaemia of 45\% found in a previous investigation, an estimated effect size of 33\% and the trial being performed at 80\% power, the necessary sample size was calculated to be 180 patients per group. We can use equation 9.18 in Julious (2009) to show why the trial chose 180 patients in each arm. $$n_A = \frac{4}{(\pi_A-\pi_B)^2},$$

Here, we have $\pi_A = 0.45$ and $\pi_B = 0.30$. If we substitute these values into the equation we obtain:
\begin{align*}
    n_A &= \frac{4}{(\pi_A-\pi_B)^2} \\
     &= \frac{4}{(0.45-0.3)^2} \\
     &= \frac{4}{0.0225} \\
    &\approx 177.8,     
\end{align*}
so we can see why the value of 180 patients in each arm was chosen.

A blinded interim analysis was prospectively planned after one-third of the calculated study population had been enrolled. 

## Results

At the interim analysis, 141 patients had been recruited into the trial. There were 78 patients in the treatment group and 63 patients in the placebo group, the results are given below:

```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
my_tbl <- tibble::tribble(
  ~"", ~RaisedcTni, ~Not.RaisedcTni, ~Total,
                          "Treatment",          31,              47,     78,
                            "Control",          23,              40,     63,
                              "Total",          54,              87,    141
  )

require(knitr)
kable(my_tbl, digits = 3, row.names = FALSE, align = "c",
              caption = NULL)

```

We see that $\approx 40\%$ patients in the treatment group have higher levels of cTnI (higher levels indicate higher levels of myocardial ischaemia), compared to $\approx 37\%$ of patients in the control group. We see that the levels of increased cTnI is greater in the treatment group than the control group, which is clearly not desirable. 

This was analysed with a $\chi^2$ test, as seen below.
```{r chisquare}
MoxonidineData <- data.frame(RaisedcTni = c(23, 31), NotRaisedcTni = c(40, 47), 
                             row.names = c("Control", "Treatment"))
chisq.test(MoxonidineData, correct = F)
```
We can see that the $p$-value calculated is 0.694, which clearly is not significant at all. Therefore, the trial was stopped due to futility (the treatment is clearly not clinically better so there is no advantage to continuing the trial until the end). 

## Assurance for this trial

The design of this trial is very traditional, very frequentist. We have a placebo (for which we have a point-estimate), a treatment (for which we have an estimate of its effects in comparison to the placebo), we have the type I error rate ($\alpha = 0.05$) and we have some power that we wish to perform the trial at (here, $1-\beta = 0.8$). As a result, we saw how when we substitute these values into the equations, we obtain 180 patients in both of the two arms.  

However, this method is sub-optimal for a number of reasons. The first reason is that this calculation assumes that the treatment is in fact better than the placebo - which we cannot possibly know as we would not be doing the trial otherwise. Therefore, the power of the test (80\%) is the conditional probability that we will find an effect, if such an effect exists. In reality, there will be times where the treatment is no better than the placebo (as was the case in this trial) so the power is a misrepresentation of how effective a trial actually is. 

The second reason is that we only have point-estimates for the placebo and the treatment effect. From historical data, we should be able to construct a distribution for the effectiveness of the placebo, and from possible phase II trials, pilot studies and in collaboration with clinical investigators, we should be able to construct a distribution for the effectiveness of the treatment.  Even if we are not very confident about our estimates in the effectiveness of the treatment, these prior beliefs can be incorporated into the distribution. 

### Trial setup

The outcome is a binary variable, we have $r_i$ successes out of $n_i$ patients for both treatments ($i=1$ for the placebo, $i=2$ for the treatment). Therefore, the hypothesis test we conduct at the end of the trial is:
\begin{align*}
    H_0 = \theta_1 = \theta_2 \\
    H_1 = \theta_1 \neq \theta_2
\end{align*}
Therefore, to calculate assurance methods for this trial design, we require prior beliefs regarding $\theta_1$ and $\theta_2$. From the information in the trial, we know that $E[\theta_1] = 0.45$. The trial investigators will be able to calculate the SD of $\theta_1$ accurately, but just for illustration, we will choose sd[$\theta_1$] = 0.1. We can find a Beta distribution which captures these beliefs by: 

```{r estBeta1}
estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}
  
estBetaParams(0.45, 0.1^2)

```

So we can see that these beliefs can be approximately captured by a Be(10.7, 13.1) distribution. 

To elicit beliefs about $\theta_2$, we can instead think about the difference between the control treatment and the experimental treatment. Let $\rho = \theta_2 - \theta_1$. We prefer to think about the difference because $\theta_1$ and $\theta_2$ are not independent. From the trial setup, we know that the clinicians believe that the experimental treatment has an effect size of 33%, this indicates that $E[\theta_2] = 0.3$ and $E[\rho]= 0.15$ Therefore, we can model $\rho \sim N(0.15, \nu)$. Again, the trial investigators will be able to choose an appropriate value for $\nu$, so for illustration we will calculate the assurance under three different scenarios (note: the third scenario has different value for the mean):

Scenario 1: $\rho \sim N(0.15, 0.0001)$

Scenario 2: $\rho \sim N(0.15, 0.01)$

Scenario 3: $\rho \sim N(0.10, 0.01)$

We can calculate assurance under the three scenarios. This can be seen in the Figure below - alongside the traditional power curve. 

```{r power+ass, message=F, warning=F}

N1vec <- seq(1,500)
N2vec <- seq(1,500)
powervec <- vector(length = 500)
for (i in 1:500){
  power <- power.prop.test(n=N1vec[i],p1=0.45,p2=0.3)
  powervec[i] <- power$power
}

plot(powervec, type = "l", ylim = c(0,1), xaxt = "n", xlab = "Total sample size", ylab = "Power/Assurance", lty=2)
axis(1, at = seq(0, 500,by = 125), labels = seq(0, 1000, by = 250))

assurancefunc <- function(n1, n2, m, v){
  n <- 10e1
  zvec <- vector(length=n)
  for (i in 1:n){
    theta1 <- rbeta(1, 10.7, 13.1) #Control
    rho <- rnorm(1, m, sd = sqrt(v))
    theta2 <- theta1 - rho #Treatment
    if (theta2 <0 ){
      zvec[i] <- NA
    } else {
      control <- rbinom(1, n1, theta1)
      treatment <- rbinom(1, n2, theta2)
      MoxonidineData <- data.frame(RaisedcTni = c(control, treatment),
              NotRaisedcTni = c(n1 - control, n2 - treatment), row.names = c("Control", "Treatment"))
      test <- chisq.test(MoxonidineData, correct = F)
      zvec[i] <- test$p.value < 0.05
    }
  }
  zvec <-  na.omit(zvec)
  mean(zvec)
}

#Scenario 1
ass1 <- vector(length = 500)
for (i in 1:500){
  ass1[i] <- assurancefunc(N1vec[i], N2vec[i], m = 0.15, v = 0.0001)
}
lo1 = loess(ass1~N1vec)
lines(predict(lo1), lty=3, col="blue")


#Scenario 2
ass2 <- vector(length = 500)
for (i in 1:500){
  ass2[i] = assurancefunc(N1vec[i], N2vec[i], m = 0.15, v = 0.01)
}
lo2 = loess(ass2~N1vec)
lines(predict(lo2), lty=4, col="red")


#Scenario 3
ass3 <- vector(length = 500)
for (i in 1:500){
  ass3[i] = assurancefunc(N1vec[i], N2vec[i], m = 0.1, v  = 0.01)
}

lo3 = loess(ass3~N1vec)
lines(predict(lo3), lty=5, col="green")

legend("bottomright", legend = c("Power", "Scenario 1", "Scenario 2", "Scenario 3"), 
       col=c("black", "blue", "red", "green"), lty=2:5)
```

In scenario 1, the prior distribution for $\rho$ indicates a strong belief that the treatment is 33% more effective than the control. This is shown by the assurance essentially being the power curve (where we assume the treatment is better). 

In scenario 2, the prior for $\rho$ indicates that the beliefs are not quite as strong as in scenario 1. This is modelled through the value of $\nu$ being larger and shown in the plot by the assurance being lower (reaches a maximum of around 80%)

In scenario 3, the prior for $\rho$ indicates that the treatment may not be as effective as 33%. This is shown in the plot as the assurance is lower than both scenarios 1 and 2.  


