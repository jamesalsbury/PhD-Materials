---
title: "Moxonidine Trial"
header-includes:
- \usepackage{caption}
always_allow_html: true
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(RColorBrewer)
library(truncnorm)
library(rstan)
```

## Introduction

This report outlines a clinical trial which can be found [\textcolor{blue}{here}](https://pubmed.ncbi.nlm.nih.gov/17968979/). The trial compared the drug moxonidine against a control in a double-blind trial. We will discuss the trial; how the sample size was calculated, how the trial was conducted and the results of the trial. 

#Talk about what is in the report
We will also retrospectively compute assurance for this trial, both before and during (in the interim analysis). Using assurance would have helped the study team in this trial as they would have been able to give distributions for their beliefs about the control and also for the effect of the experimental treatment. If they were unsure of their beliefs about either then this could be modelled by the distributions and the assurance calculations would reflect this. Therefore everyone involved in the trial would be more informed, from the sponsors to the study team. 


## Background

Myocardial ischaemia is the leading cause of mortality after surgery on patients with coronary artery disease. In the trial, patients were randomly assigned the treatment drug **moxonidine** or a control (with ratio 1:1) to be taken the morning before surgery and on days 1 to 4 after surgery. Study medication was administered by a member of the team blinded to treatment allocation. The endpoint of the trial was measuring the difference in levels of cTnI before surgery and 7 days post surgery, an increase of 2$\mu$g/l of cTnI was interpreted as being clinically significant in increasing the probability of myocardial ischaemia. Therefore, an increase of 2$\mu$g/l of cTnI is an undesirable outcome and any increase less than 2$\mu$g/l of cTnI is a desirable outcome. An incidence level of 45% was found in a previous investigation for the control and the clinicians believed the experimental treatment (moxonidine) would decrease incidence levels to 30%. 


## Trial Design
Based on the above information, a desired Type I error rate $\alpha$ of 0.05 and trial being performed at 80\% power, the necessary sample size was calculated to be 180 patients per group. We can use equation 9.18 in Julious (2009) to show why the trial chose 180 patients in each arm. $$n_A = \frac{4}{(\pi_A-\pi_B)^2},$$

Here, we have $\pi_A = 0.45$ and $\pi_B = 0.30$. If we substitute these values into the equation we obtain:
\begin{align*}
    n_A &= \frac{4}{(\pi_A-\pi_B)^2} \\
     &= \frac{4}{(0.45-0.3)^2} \\
     &= \frac{4}{0.0225} \\
    &\approx 177.8,     
\end{align*}
so we can see why the value of 180 patients in each arm was chosen.

A blinded interim analysis was prospectively planned after one-third of the calculated study population had been enrolled. The decision-rules performed at the interim analysis are unknown, but the trial was stopped for futility (citing a high p-value). 

## Results

At the interim analysis, 141 patients had been recruited into the trial (just over the one-third of patients, as specified before the trial). There were 78 patients in the treatment group and 63 patients in the control group, the results are given below:

```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
my_tbl <- tibble::tribble(
  ~"", ~"Control (n=63)", ~"Treatment (n=78)",
                          "Not raised cTnI (desirable)",     "40(63%)",         "47(60%)",              
                            "Raised cTnI (undesirable)",       "23(37%)",    "31(40%)"           
                              
  )

require(knitr)
kable(my_tbl, digits = 3, row.names = FALSE, align = "c",
              caption = NULL)

```


At the interim analysis, We see that $\approx 40\%$ patients in the treatment group have higher levels of cTnI (higher levels indicate higher levels of myocardial ischaemia), compared to $\approx 37\%$ of patients in the control group. We see that the levels of increased cTnI is greater in the treatment group than the control group, which is clearly not desirable (nor what the study team had planned for).

This can be analysed with a $\chi^2$ test, as seen below.

```{r chisquare }
MoxonidineData <- data.frame(RaisedcTni = c(23, 31), NotRaisedcTni = c(40, 47),
                             row.names = c("Control", "Treatment"))
chisq.test(MoxonidineData, correct = F)
```

We can see that the $p$-value calculated is 0.694, which clearly is not significant at all. 

## Conditional power

As we have a trial with an interim analysis, we can calculate conditional power. To perform a conditional power calculation, the remaining unknown patient outcomes are simulated. It is not clear how these values should be simulated, there are (usually) three different options the statistician can make, we assume that the remaining patients will follow: 1) the same trend as the observed patients, 2) the trend elicited before the trial began and 3) the null hypothesis. We will calculate conditional power according to all three of these assumptions

### Assumption 1 (realistic)

Here, we assume the remaining patients will follow the same trend as the data accrued so far. That is, the control group has an incidence level of 37% and the treatment group has an incidence level of 40%. We can simulate data according to this, and then calculate the proportion of the trials that have a "successful" outcome. 


```{r cp1, echo=F}
testvec <- rep(NA, 5000)
for (i in 1:length(testvec)){
  remainingControl <- rbinom(117, size = 1, prob = 23/63)
remainingTreatment <- rbinom(102, size = 1, prob = 31/78)
MoxonidineData <- data.frame(RaisedcTni = c(23+sum(remainingControl==1), 31+sum(remainingTreatment==1)), NotRaisedcTni = c(40+sum(remainingControl==0), 47+sum(remainingTreatment==0)),
                             row.names = c("Control", "Treatment"))
test <- chisq.test(MoxonidineData, correct = F)
testvec[i] <- test$p.value<0.05
}
mean(testvec)

```

### Assumption 2 (optimistic)

Here, we assume the remaining data will follow that of the clinicians beliefs before the trial started: control will have an incidence rate of 45% and treatment will have a lower incidence rate of 30%. 

```{r cp2, echo=F}
testvec <- rep(NA, 5000)
for (i in 1:length(testvec)){
remainingControl <- rbinom(117, size = 1, prob = 0.45)
remainingTreatment <- rbinom(102, size = 1, prob = 0.3)
MoxonidineData <- data.frame(RaisedcTni = c(23+sum(remainingControl==1), 31+sum(remainingTreatment==1)), NotRaisedcTni = c(40+sum(remainingControl==0), 47+sum(remainingTreatment==0)),
                             row.names = c("Control", "Treatment"))
test <- chisq.test(MoxonidineData, correct = F)
testvec[i] <- test$p.value<0.05
}
mean(testvec)
```

### Assumption 3 (pessimistic)

Here, we assume that the remaining data will come from the null hypothesis. That is, the control and treatment incidence rates will both be 45%. 

```{r cp3, echo=F}
testvec <- rep(NA, 5000)
for (i in 1:length(testvec)){
remainingControl <- rbinom(117, size = 1, prob = 0.45)
remainingTreatment <- rbinom(102, size = 1, prob = 0.45)
MoxonidineData <- data.frame(RaisedcTni = c(23+sum(remainingControl==1), 31+sum(remainingTreatment==1)), NotRaisedcTni = c(40+sum(remainingControl==0), 47+sum(remainingTreatment==0)),
                             row.names = c("Control", "Treatment"))
test <- chisq.test(MoxonidineData, correct = F)
testvec[i] <- test$p.value<0.05
}
mean(testvec)
```


So, we see that in all three of the scenarios, the conditional power has greatly reduced from the original power planned for before the trial was conducted (80%). From these results, we can see why the trial was stopped for futility. 


## Making this trial Bayesian

### Trial design stage

The design of this trial is very traditional, very frequentist. We have a placebo (for which we have a point-estimate), a treatment (for which we have an estimate of its effects in comparison to the placebo), we have the type I error rate ($\alpha = 0.05$) and we have some power that we wish to perform the trial at (here, $1-\beta = 0.8$). As a result, we saw how when we substitute these values into the equations, we obtain 180 patients in both of the two arms.

However, this method is sub-optimal for a number of reasons. The first reason is that this calculation assumes that the treatment is in fact better than the placebo - which we cannot possibly know as we would not be doing the trial otherwise. Therefore, the power of the test (80\%) is the conditional probability that we will find an effect, if such an effect exists. In reality, there will be times where the treatment is no better than the placebo (as it seemed was the case in this trial) so the power is a misrepresentation of how effective a trial actually is.

The second reason is that we only have point-estimates for the placebo and the treatment effect. From historical data, we should be able to construct a distribution for the effectiveness of the placebo, and from possible phase II trials, pilot studies and in collaboration with clinical investigators, we should be able to construct a distribution for the effectiveness of the treatment.  Even if we are not very confident about our estimates in the effectiveness of the treatment, these prior beliefs can be incorporated into the distribution.

### Trial setup

The outcome is a binary variable, we have $r_i$ successes (note: a 'success' here is **not** a desirable outcome) out of $n_i$ patients for both treatments ($i=1$ for the placebo, $i=2$ for the treatment). Therefore, the hypothesis test we conduct at the end of the trial is:
\begin{align*}
    H_0 = \theta_1 = \theta_2 \\
    H_1 = \theta_1 \neq \theta_2
\end{align*}
Therefore, to calculate assurance methods for this trial design, we require prior beliefs regarding $\theta_1$ and $\theta_2$. From the information in the trial, we know that $E[\theta_1] = 0.45$. The trial investigators will be able to calculate the SD of $\theta_1$ accurately, but for illustration, we will choose sd[$\theta_1$] = 0.1. We can find a Beta distribution (we use a Beta distribution as it only takes values [0,1] which is desirable for a proportion) which captures these beliefs by:

```{r estBeta1}
estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}

estBetaParams(0.45, 0.1^2)

```

So we can see that these beliefs can be approximately captured by a Be(10.7, 13.1) distribution.

To elicit beliefs about $\theta_2$, we can instead think about the difference between the control treatment and the experimental treatment. Let $\rho = \theta_1 - \theta_2$. We prefer to think about the difference as $\theta_1$ and $\theta_2$ are not independent. From the trial setup, we know that the clinicians believe that the experimental treatment has an absolute effect size of 15%, this indicates that $E[\theta_2] = 0.3$ and $E[\rho]= 0.15$. Therefore, we can model $\rho \sim N(0.15, \nu)$. Again, the trial investigators will be able to choose an appropriate value for $\nu$, so for illustration we will calculate the assurance under four different scenarios (note: the third scenario has different value for the mean):

Scenario 1: $\rho \sim N(0.15, 0.0001)$

Scenario 2: $\rho \sim N(0.15, 0.01)$

Scenario 3: $\rho \sim N(0.10, 0.01)$

Scenario 4: $\rho \sim Unif(\theta_1-1 \text{, } \theta_1)$

We can calculate assurance under the four scenarios. This can be seen in the figure below - alongside the traditional power curve.

```{r power+ass, message=F, warning=F, echo=F}

N1vec <- floor(seq(50, 500, length=50))
N2vec <- floor(seq(50,500, length = 50))
powervec <- rep(NA, length = length(N1vec))
for (i in 1:length(powervec)){
  power <- power.prop.test(n=N1vec[i],p1=0.45,p2=0.3)
  powervec[i] <- power$power
}


plot(N1vec, powervec, type = "l", ylim = c(0,1), xlab = "Total sample size", xaxt = "n",
     ylab = "Power/Assurance", lty=1)
axis(1, at = seq(0, 500,by = 100), labels = seq(0, 1000, by = 200))

assurancefunc <- function(n1, n2, m, v){
  n <- 20e1
  zvec <- rep(NA, length=n)
  for (i in 1:n){
    theta1 <- rbeta(1, 10.7, 13.1) #Control
    rho <- truncnorm::rtruncnorm(1, mean = m, sd = sqrt(v), a = (theta1-1), b = theta1)
    theta2 <- theta1 - rho #Treatment
    control <- rbinom(1, n1, theta1)
    treatment <- rbinom(1, n2, theta2)
    MoxonidineData <- data.frame(RaisedcTni = c(control, treatment),
              NotRaisedcTni = c(n1 - control, n2 - treatment),
              row.names = c("Control", "Treatment"))
    test <- chisq.test(MoxonidineData, correct = F)
    zvec[i] <- test$p.value < 0.05
  }
  mean(zvec)
}

#Scenario 1
ass1 <- rep(NA, length=length(N1vec))
for (i in 1:length(ass1)){
  ass1[i] <- assurancefunc(N1vec[i], N2vec[i], m = 0.15, v = 0.0001)
}
lo1 <- loess(ass1~N1vec)
lines(N1vec, predict(lo1), lty=2, col="blue")

#Scenario 2
ass2 <- rep(NA, length=length(N1vec))
for (i in 1:length(ass2)){
  ass2[i] <- assurancefunc(N1vec[i], N2vec[i], m = 0.15, v = 0.01)
}
lo2 <- loess(ass2~N1vec)
lines(N1vec, predict(lo2), lty=3, col="red")


#Scenario 3
ass3 <- rep(NA, length=length(N1vec))
for (i in 1:length(ass3)){
  ass3[i] <- assurancefunc(N1vec[i], N2vec[i], m = 0.1, v  = 0.01)
}

lo3 <- loess(ass3~N1vec)
lines(N1vec, predict(lo3), lty=4, col="green")

DesignAssuranceFuncNonInform <- function(){

  #We calculate the assurance for user-specified n1 and n2
  assurancefunc <- function(n1, n2){
    n <- 20e1
    zvec <- vector(length=n)
    for (i in 1:n){
      theta1 <- rbeta(1, 10.7, 13.1) #Control
      rho <- runif(n = 1, min = theta1-1, max = theta1)
      theta2 <- theta1 - rho #Treatment
      control <- rbinom(1, n1, theta1)
      treatment <- rbinom(1, n2, theta2)
      MoxonidineData <- data.frame(RaisedcTni = c(control, treatment),
                                     NotRaisedcTni = c(n1 - control, n2 - treatment),
                                     row.names = c("Control", "Treatment"))
      test <- chisq.test(MoxonidineData, correct = F)
      zvec[i] <- test$p.value<0.05
    }
    mean(zvec)
  }

  #We compute the assurance for a range of different n1, n2 values
  assurance <- rep(NA, length = 50)
  N1vec <- floor(seq(50, 500, length=50))
  N2vec <- floor(seq(50,500, length = 50))
  for (i in 1:length(N1vec)){
    assurance[i] <- assurancefunc(N1vec[i], N2vec[i])
  }

  #Smooth the output
  lo <- loess(assurance~N1vec)
  return(lo)
}
lines(N1vec, predict(DesignAssuranceFuncNonInform()), lty=5, col="yellow")

legend("bottomright", legend = c("Power", "Scenario 1", "Scenario 2", "Scenario 3", "Scenario 4"),
       col=c("black", "blue", "red", "green", "yellow"), lty=1:5)
```

In scenario 1, the prior distribution for $\rho$ indicates a strong belief that the treatment is 33% more effective than the control. This is shown by the assurance essentially being the power curve (where we assume the treatment is better).

In scenario 2, the prior for $\rho$ indicates that the beliefs are not quite as strong as in scenario 1. This is modelled through the value of $\nu$ being larger and shown in the plot by the assurance being lower (reaches a maximum of around 80%)

In scenario 3, the prior for $\rho$ indicates that the treatment may not be as effective as 33%. This is shown in the plot as the assurance is lower than both scenarios 1 and 2.


### Interim analysis stage

We can also perform assurance calculations during the trial. This feels natural in a Bayesian paradigm; we have prior distributions (about $\theta_1$ and $\rho$) and some data, which we can combine together to obtain a posterior distribution.

The following four plots show the four different scenarios; in each plot we have the power, the assurance at the design stage and the assurance at the interim analysis stage. The total sample sizes only reach a maximum of 360 (180 in each arm) here, as this was the number of patients planned to be enrolled in the trial.


```{stan output.var="ex1", echo=F}
data {
  int<lower=0> cE;               // control events
  int<lower=0> cN;               // number of patients in control group
  int<lower=0> tE;               // treatment events
  int<lower=0> tN;               // number of patients in treatment group
}

parameters {
  real<lower=0, upper=1> theta1; // chance of success in control group
  real rho;                      // difference between treatment and control (theta1-theta2)
}

transformed parameters{
  real<lower=0, upper=1> theta2; // chance of success in treatment group
  theta2 = theta1 - rho;
}

model {
  theta1 ~ beta(10.7, 13.1);
  rho ~ normal(0.15, 0.01);
  cE ~ binomial(cN, theta1);
  tE ~ binomial(tN, theta2);
}

generated quantities {
  int<lower=0> controlevents;
  int<lower=0> treatmentevents;
  controlevents = binomial_rng(117, theta1);
  treatmentevents = binomial_rng(102, theta2);
}


```


```{r interim, echo=F}
 MoxonidineData <- data.frame(cE = 23, tE = 31, cN = 63, tN = 78) 
 exampleData <- list(cE = MoxonidineData$cE, cN = MoxonidineData$cN, 
            tE = MoxonidineData$tE, tN = MoxonidineData$tN) 
 
 sampling_iterations <- 1e5
 fit <- sampling(ex1,
 data = exampleData,
 chains = 1,
 iter = sampling_iterations,
 warmup = sampling_iterations/4,
 refresh=0)
 

 testvec <- rep(NA, 1e5)
 for (i in 1:1e5){
  controlevents <- fit@sim$samples[[1]][[4]][i]
  treatmentevents <- fit@sim$samples[[1]][[5]][i]
  MoxonidineData <- data.frame(RaisedcTni = c(23+controlevents, 31+treatmentevents), NotRaisedcTni 
                               =c(40+(117-controlevents), 47+(102-treatmentevents)),
                                   row.names = c("Control", "Treatment"))
  test <- chisq.test(MoxonidineData, correct = F)
  testvec[i] <- test$p.value<0.05
 }
 mean(testvec)
 
```

###########################################################################
##Look at other priors for the BPP part!!
###########################################################################

