---
title: "LikelihoodWeib"
header-includes:
   - \usepackage{bm}
output: html_document
date: '2022-07-22'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(stats4)
library(rstan)
library(rjags)
library(ggmcmc)
```

## R Markdown

We have some data $\textbf{x}= (x_{c,1},\ldots,x_{c,n}, x_{t,1}, \ldots, x_{t, m})$. We are tasked with finding the most likely values for the parameters $\lambda_1$, $\gamma_1$, $\lambda_2$, $\gamma_2$ and $T$ if we assume they come from the following survival functions

$$S_c(t) = \text{exp}\{-(\lambda_2t)^{\gamma_2}\}$$

$$S_t(t) = \text{exp}\{-(\lambda_2t)^{\gamma_2}\}\mathbb{1}_{t\leq T}+\exp\{-(\lambda_2T)^{\gamma_2}-\lambda_1^{\gamma_1}(t^{\gamma_1}-T^{\gamma_1})\}\mathbb{1}_{t>T}$$

We have the relationship

$$f(t) = \frac{d}{dt}[1-S(t)]$$

Therefore, the above survival probabilities can be manipulated to give the following densities

$$f_c(t) = \frac{\gamma_2(\lambda_2t)^{\gamma_2}\text{exp}\{-(\lambda_2t)^{\gamma_2}\}}{t}$$
$$f_t(t) = \frac{\gamma_2(\lambda_2t)^{\gamma_2}\text{exp}\{-(\lambda_2t)^{\gamma_2}\}}{t}\mathbb{1}_{t\leq T}+\gamma_1\lambda_1^{\gamma_1}t^{\gamma_1-1}\text{exp}\{-\lambda_1^{\gamma_1}(t^{\gamma_1}-T^{\gamma_1})-(T\lambda_2)^{\gamma_2}\}\mathbb{1}_{t>T}$$

Therefore, the joint density is


\begin{align}
p(\textbf{x}|\lambda_1, \gamma_1,\lambda_2,\gamma_2, T) &= p(x_{c,1},\ldots,x_{c,n}|\lambda_2, \gamma_2) \times p(x_{t,1},\ldots,x_{t,m}|\lambda_1, \gamma_1,\lambda_2,\gamma_2, T) \\
&= p(x_{c,1},\ldots,x_{c,n}|\lambda_2, \gamma_2) \times p(x_{t,1},\ldots,x_{t,j}|\lambda_2, \gamma_2) \times p(x_{t,j+1},\ldots,x_{t,m}|\lambda_1, \gamma_1,\lambda_2,\gamma_2, T),
\end{align}

where $x_{t,j}$ is the largest observed $x$ in the treatment group before T.

The joint likelihood is 

\begin{align}
\mathcal{L}(\lambda_1, \gamma_1,\lambda_2,\gamma_2, T|x_{c,1},\ldots,x_{c,n}, x_{t,1}, \ldots, x_{t, m}) &= \prod^n_{i=1} \frac{\gamma_2(\lambda_2x_{c,i})^{\gamma_2}\text{exp}\{-(\lambda_2x_{c,i})^{\gamma_2}\}}{x_{c,i}} \times \prod^j_{k=1}  \frac{\gamma_2(\lambda_2x_{t,k})^{\gamma_2}\text{exp}\{-(\lambda_2x_{t,k})^{\gamma_2}\}}{x_{t,k}} \times \prod^m_{p=j+1}
\gamma_1\lambda_1^{\gamma_1}x_{t,p}^{\gamma_1-1}\text{exp}\{-\lambda_1^{\gamma_1}(x_{t,p}^{\gamma_1}-T^{\gamma_1})-(T\lambda_2)^{\gamma_2}\} \\


&= \gamma_2^n\lambda_2^{n\gamma_2}\{\prod_{i=1}^nx_{c,i}\}^{\gamma_2}\text{exp}\{-\lambda_2^{\gamma_2}\sum^n_{i=1}(x_{c,i}^{\gamma_2})\}\prod^n_{i=1}\frac{1}{x_{c,i}} \times \gamma_2^j\lambda_2^{j\gamma_2}\{\prod_{k=1}^jx_{t,k}\}^{\gamma_2}\text{exp}\{-\lambda_2^{\gamma_2}\sum^j_{k=1}(x_{t,k}^{\gamma_2})\}\prod^j_{k=1}\frac{1}{x_{t,k}} \times \gamma_1^{m-j}\lambda_1^{\gamma_1(m-j)}\{\prod^m_{p=j+1}x_{t,p}\}^{\gamma_1-1}\text{exp}\{-\lambda_1^{\gamma_1}\sum^m_{p=j+1}(x_{t,p}^{\gamma_1})+(m-j)\big[(\lambda_1T)^{\gamma_1}-(\lambda_2T)^{\gamma_2}\big]\}
\end{align}

We find the log-likelihood

\begin{align}
\text{log} \mathcal{L}(\lambda_1, \gamma_1,\lambda_2,\gamma_2, T|x_{c,1},\ldots,x_{c,n}, x_{t,1}, \ldots, x_{t, m}) &= n\text{log}\gamma_2 + n\gamma_2\text{log}\lambda_2+\gamma_2\sum^n_{i=1}\text{log}x_{c,i}-\lambda_2^{\gamma_2}\sum^{n}_{i=1}x_{c,i}^{\gamma_2}+\sum^{n}_{i=1}\text{log}\frac{1}{x_{c,i}} + j\text{log}\gamma_2 + j\gamma_2\text{log}\lambda_2+\gamma_2\sum^j_{k=1}\text{log}x_{t,k}-\lambda_2^{\gamma_2}\sum^{j}_{k=1}x_{t,k}^{\gamma_2}+\sum^{j}_{k=1}\text{log}\frac{1}{x_{t,k}}+(m-j)\text{log}\gamma_1+\gamma_1(m-j)\text{log}\lambda_1+(\gamma_1-1)\sum^m_{p=j+1}\text{log}x_{t,p} - \lambda_1^{\gamma_1}\sum^m_{p=j+1}(x_{t,p}^{\gamma_1})+(m-j)\big[(\lambda_1T)^{\gamma_1}-(\lambda_2T)^{\gamma_2}\big]
\end{align}


We can ensure that this is the correct log-likelihood with the following code

```{r, eval=T}

set.seed(42)
#Setting up the correct parameters - we would not know this in practice

lambda1 <- 0.04
lambda2 <- 0.08
gamma2 <- 0.8
gamma1 <- 0.8
bigT <- 6

#Sample sizes in each group
n1 <- 100
n2 <- 100

#When is the IA time?
IATime <- 100

#Simulating the control and treatment data - again, we would not normally know the underlying structure, but for illustration this is okay
#Control
controldata <- rweibull(n1, gamma2, 1/lambda2)
#Treatment
CP <- exp(-(lambda2*bigT)^gamma2)[[1]]
u <- runif(n2)
suppressWarnings(treatmentdata <- ifelse(u>CP, (1/lambda2)*exp(1/gamma2*log(-log(u))), exp((1/gamma1)*log(1/(lambda1^gamma1)*(-log(u)-(lambda2*bigT)^gamma2+lambda1^gamma1*bigT*gamma1)))))

combinedData <- data.frame(time = c(controldata, treatmentdata), group = c(rep("Control", n1), rep("Treatment", n2)))

combinedData$event <- combinedData$time<IATime

combinedData$time[combinedData$time>IATime] <- IATime

controlkm <- survfit(Surv(time, event)~group, data = combinedData)

plot(controlkm)

#Using the data to find the parameters we have defined
n <- length(controldata)
m <- length(treatmentdata)
treatmentdata <- sort(treatmentdata)

#Coding the log-likelihood function we derived
nll <- function(bigTEst, lambda2Est, gamma2Est, lambda1Est, gamma1Est){
  j <- sum(treatmentdata < bigTEst)
  mysum <-0
  for (i in 1:n){
    mysum <- mysum+log(controldata[i])
  }
  
  mysum1 <-0
  for (i in 1:n){
    mysum1 <- mysum1+controldata[i]^gamma2Est
  }
  
  mysum2 <-0
  for (i in 1:n){
    mysum2 <- mysum2+log(1/controldata[i])
  }

  mysum3 <- 0
  for (i in 1:j){
    mysum3 <- mysum3 + log(treatmentdata[i])
  }

  mysum4 <- 0
  for (i in 1:j){
    mysum4 <- mysum4 + treatmentdata[i]^gamma2Est
  }

  mysum5 <- 0
  for (i in 1:j){
    mysum5 <- mysum5 + log(1/treatmentdata[i])
  }

  mysum6 <- 0
  for (i in (j+1):m){
    mysum6 <- mysum6 + log(treatmentdata[i])
  }

  mysum7 <- 0
  for (i in (j+1):m){
    mysum7 <- mysum7 + treatmentdata[i]^gamma1Est
  }

  loglikelihood <- n*log(gamma2Est)+n*gamma2Est*log(lambda2Est)+gamma2Est*mysum-lambda2Est^gamma2Est*mysum1+mysum2+ j*log(gamma2Est)+j*gamma2Est*log(lambda2Est)+gamma2Est*mysum3-lambda2Est^gamma2Est*mysum4+mysum5+ (m-j)*log(gamma1Est)+gamma1Est*(m-j)*log(lambda1Est)+(gamma1Est-1)*mysum6-lambda1Est^gamma1Est*
  mysum7+(m-j)*((lambda1Est*bigTEst)^gamma1Est-(lambda2Est*bigTEst)^gamma2Est)
  
  #Returning the negative ll as this is what the mle() function expects
 return(-loglikelihood)
}

#Finding the maximum likelihood estimators for T, lambda2 and lambda1
est <- stats4::mle(minuslogl = nll, start = list(bigTEst=6, lambda2Est = 0.08, gamma2Est = 0.8, lambda1Est = 0.04, gamma1Est = 0.8), lower=  list(bigTEst=0.5, lambda2Est = 0.0001, gamma2Est = 0.001, lambda1Est = 0.001, gamma1Est = 0.001), upper = list(bigTEst = 60))

#Showing the output of the mle() function
#Seems pretty good!
est

nlloptim <- function(x){
 j <- sum(treatmentdata < x[1])
  mysum <-0
  for (i in 1:n){
    mysum <- mysum+log(controldata[i])
  }
  
  mysum1 <-0
  for (i in 1:n){
    mysum1 <- mysum1+controldata[i]^x[3]
  }
  
  mysum2 <-0
  for (i in 1:n){
    mysum2 <- mysum2+log(1/controldata[i])
  }

  mysum3 <- 0
  for (i in 1:j){
    mysum3 <- mysum3 + log(treatmentdata[i])
  }

  mysum4 <- 0
  for (i in 1:j){
    mysum4 <- mysum4 + treatmentdata[i]^x[3]
  }

  mysum5 <- 0
  for (i in 1:j){
    mysum5 <- mysum5 + log(1/treatmentdata[i])
  }

  mysum6 <- 0
  for (i in (j+1):m){
    mysum6 <- mysum6 + log(treatmentdata[i])
  }

  mysum7 <- 0
  for (i in (j+1):m){
    mysum7 <- mysum7 + treatmentdata[i]^x[4]
  }

  loglikelihood <- n*log(x[3])+n*x[3]*log(x[2])+x[3]*mysum-x[2]^x[3]*mysum1+mysum2+ j*log(x[3])+j*x[3]*log(x[2])+x[3]*mysum3-x[2]^x[3]*mysum4+mysum5+ (m-j)*log(x[4])+x[4]*(m-j)*log(x[4])+(x[4]-1)*mysum6-x[4]^x[4]*
  mysum7+(m-j)*((x[4]*x[1])^x[4]-(x[2]*x[1])^x[3])
  
  #Returning the negative ll as this is what the mle() function expects
 return(-loglikelihood) 
 
}


#SA <- GenSA(par = c(15, 0.01, 0.1, 0.01, 0.1), fn = nlloptim, lower=c(1, 0.001, 0.001, 0.001, 0.001), upper=c(60, 10, 10, 10, 10))

#SA$par

n <- n1
m <- n1+n2

#Let us try and code this up in JAGS


modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(gamma2)+gamma2*log(lambda2*datTimes[i])-(lambda2*datTimes[i])^gamma2-log(datTimes[i]), -(lambda2*datTimes[i])^gamma2)
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(gamma2)+gamma2*log(lambda2*datTimes[i])-(lambda2*datTimes[i])^gamma2-log(datTimes[i]), log(gamma1)+gamma1*log(lambda1)+(gamma1-1)*log(datTimes[i])-lambda1^gamma1*(datTimes[i]^gamma1-bigT^gamma1)-(bigT*lambda2)^gamma2), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i])^gamma2, -(lambda2*bigT)^gamma2-lambda1^gamma1*(datTimes[i]^gamma1-bigT^gamma1)))
  }
  
    lambda1 ~ dbeta(1,1)T(0,)
    lambda2 ~ dbeta(1,1)T(0,)
    gamma1 ~ dbeta(1,1)T(0,)
    gamma2 ~ dbeta(1,1)T(0,)
    bigT ~ dnorm(6, 0.1)T(0,)
     
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = combinedData$time, datEvent = combinedData$event, n= n, m=m)) 
                   
                   
update(model, n.iter=1000)
output=coda.samples(model=model, variable.names=c("lambda1", "lambda2", "gamma1", "gamma2", "bigT"), n.iter = 10000)


summary(output)
plot(output)




```

```{stan output.var="ia1", eval=F}

functions {
  real expmodel_log(vector Y, int controlLength, int treatmentLength, real lambdac, real lambdat, real bigT) {
    real loglik;
    int j;
    int n;
    int m;
    vector[controlLength] controlData;
    vector[treatmentLength] treatmentData;
    n = controlLength;
    m = treatmentLength;
    controlData = Y[1:n];
    treatmentData = Y[(n+1):(n+m)];
    j=0;
    for (i in 1:m){
      if (treatmentData[i]<bigT){
        j = j + 1;
      }
    }
   
    loglik = (n+j)*log(lambdac)-lambdac*(sum(controlData)+sum(treatmentData[1:j]))+
  (m-j)*(log(lambdat)+lambdat*bigT-lambdac*bigT) - lambdat*sum(treatmentData[(j+1):(m)]);
    return loglik;
  }
}

data {
  int controlLength;
  int treatmentLength;
  vector[controlLength+treatmentLength] Y;
}

parameters {
  real <lower=0> lambdac;
  real <lower=0> lambdat;
  real <lower=0> bigT;
}

model {
  lambdac ~ beta(1, 1);
  lambdat ~ beta(1, 1);
  bigT ~ normal(6, 1);
  Y ~ expmodel(controlLength, treatmentLength, lambdac, lambdat, bigT);
}

```


```{r, eval=F}

lambda1 <- 0.04
lambda2 <- 0.08
bigT <- 6

#Sample sizes in each group
n1 <- 500
n2 <- 500

#Simulating the control and treatment data - again, we would not normally know the underlying structure, but for illustration this is okay
#Control
controlData <-rexp(n1, lambda2)
#Treatment
CP <- exp(-(lambda2*bigT))[[1]]
u <- runif(n2)
suppressWarnings(treatmentData <- ifelse(u>CP, -(1/lambda2)*log(u), (1/lambda1)*(-log(u)-bigT*(lambda2-lambda1))))

n <- length(controlData)
m <- length(treatmentData)
treatmentData <- sort(treatmentData)

combinedData <- c(controlData, treatmentData)

 sampling_iterations <- 1e3
 fit <- sampling(ia1,
 data = list(Y = combinedData, controlLength=n, treatmentLength=m),
 chains = 1,
 iter = sampling_iterations,
 warmup = sampling_iterations/4,
 refresh=0)
 
 summary(fit)
 
 samples <- ggmcmc::ggs(fit)
 ggmcmc::ggs_pairs(samples)
 
 ggmcmc::ggs_caterpillar(samples, thick_ci = c(0.25,0.75))
 
 ggmcmc::ggs_traceplot(samples)
```


https://my.vanderbilt.edu/jeffannis/files/2016/06/AnnisMillerPalmeri2016.pdf







