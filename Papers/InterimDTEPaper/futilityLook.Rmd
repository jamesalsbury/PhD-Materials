---
title: "futilityLook"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
```

We are looking at including futility looks into the clinical trial. We recreate the results from [Korn and Freidlin (2018)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6366306/pdf/JCO.2018.77.7144.pdf). We have the following setup:
We require 512 events, a sample size of 680. We assume the hazard ratio is 0.75, we have uniform recruitment for 34 months. We have exponential survival in the control arm, with a median survival of $\approx$ 12.5 months. We introduce three futility rules:

1) Wieand rule
* At 50% information, stop if the observed HR > 1
* At 75% information, stop if the observed HR > 1

2) O'Brien-Fleming $\beta$ spending
* At 33% information, stop if the observed HR > 0.998
* At 67% information, stop if the observed HR > 0.913

3) Proposed rule - by Korn and Freidlin
* At 50% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1
* At 75% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1

This is the results for when we do not have DTE present

```{r, echo=F}
#Adding in the futility rules
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTime <- 34
lambdac <- 1/18
lambdat <- lambdac*HR

nSims <- 1e2
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), rexp(nPatients/2, rate = lambdat)), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData$time <- combinedData$time + runif(nPatients, min = 0, max = recTime)
  
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  powervec[i] <- test$chisq > qchisq(0.95, 1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
  }
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  #print(deltad)
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

knitr::kable(simResults)
```

This is the results for when we have DTE (3 months delay)

```{r, echo=F}
#Adding in the futility rules
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTime <- 34
lambdac <- 1/18
lambdat <- lambdac*HR
lengthDelay <- 3

nSims <- 1e2
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData$time <- combinedData$time + runif(nPatients, min = 0, max = recTime)
  
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  powervec[i] <- test$chisq > qchisq(0.95, 1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  #print(deltad)
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

knitr::kable(simResults)
```

This is the results for when we have DTE (6 months delay)

```{r, echo=F}
#Adding in the futility rules
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTime <- 34
lambdac <- 1/18
lambdat <- lambdac*HR
lengthDelay <- 6

nSims <- 1e2
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData$time <- combinedData$time + runif(nPatients, min = 0, max = recTime)
  
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  powervec[i] <- test$chisq > qchisq(0.95, 1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  #print(deltad)
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

knitr::kable(simResults)
```

This is the results for when the HR is 1 (no effect)

```{r, echo=F}
#Adding in the futility rules
nEvents <- 512
nPatients <- 680
HR <- 1
recTime <- 34
lambdac <- 1/18
lambdat <- lambdac*HR
lengthDelay <- 6

nSims <- 1e2
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData$time <- combinedData$time + runif(nPatients, min = 0, max = recTime)
  
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  powervec[i] <- test$chisq > qchisq(0.95, 1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  #print(deltad)
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    if (test$chisq > qchisq(0.95, 1)){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

knitr::kable(simResults)
```



