---
title: "futilityLook"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(truncnorm)
```

We are looking at including futility looks into the clinical trial. We recreate the results from [Korn and Freidlin (2018)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6366306/pdf/JCO.2018.77.7144.pdf). We have the following setup:
We require 512 events, a sample size of 680. We assume the hazard ratio is 0.75, we have uniform recruitment for 34 months. We have exponential survival in the control arm, with a median survival of 12 months. We introduce three futility rules:

1) Wieand rule
* At 50% information, stop if the observed HR > 1
* At 75% information, stop if the observed HR > 1

2) O'Brien-Fleming $\beta$ spending
* At 33% information, stop if the observed HR > 0.998
* At 67% information, stop if the observed HR > 0.913

3) Proposed rule - by Korn and Freidlin
* At 50% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1
* At 75% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1

```{r, echo=F, eval = F}
futilityPowerFunc <- function(HR, lengthDelay){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

nSims <- 1e3
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  powervec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```
These are the results seen when HR is 0.75 and there is no delay

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 0))
```

These are the results seen when HR is 0.75 and there is a delay of 3 months

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 3))
```

These are the results seen when HR is 0.75 and there is a delay of 6 months

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 6))
```

These are the results seen when HR is 1 (and no delay)

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 1, lengthDelay = 0))
```

These are the results seen when HR is 1.3 (and no delay)

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 1.3, lengthDelay = 0))
```

# Assurance

We can add some uncertainty to the parameters to see if this makes a difference to the calculations shown for futility

```{r, echo=F, eval = F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 1e3
assvec <- rep(NA, nSims)
Wieandassvec <- rep(NA, nSims)
OBFassvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandassvec[i] <- 4
    } else {
      Wieandassvec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFassvec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFassvec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFassvec[i] <- 4
    } else {
      OBFassvec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Wieand = c(mean(Wieandassvec==4), mean(Wieandcensvec)), OBF = c(mean(OBFassvec==4), mean(OBFcensvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(0, 0^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 0, lengthDelaysd = 0))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.01^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.01, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(6, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 6, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(1, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 1, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

# Doing the Bayesian updating at the interim

We need to find a way of updating the prior distributions at any interim analysis


```{r, eval = F}
library(rjags)

bigTFunc <- function(bigTsd){
  HRVec <- rep(NA, 100)

for (j in 1:100){
  HR <- rnorm(1, mean = 0.75, sd = 0.05)
bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = bigTsd)
lambdac <- -log(0.5)/12
lambdat  <- lambdac*HR
nEvents <- 512
nPatients <- 680
recTime <- 34

CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]

  samplevec <- sample(1:nPatients)

  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #Look at a futility stop 50% the way through the events
  
  IAData <- combinedData
  
  IATime  <- IAData[nEvents*0.5,]$time
  
  IAData$status <- IAData$time<=IATime
  
  IAData[IAData$status==F,]$time <- IATime
  
  IAData <- IAData[order(IAData$group),]

  controlkm <- survfit(Surv(time, status)~group, data = IAData)
# 
#plot(controlkm, col=c("blue", "red"))

#legend("topright", legend = c("Control", "Treatment"), col = c("blue", "red"), lty=1)

 coxmodel <- coxph(Surv(time, status)~group, data = IAData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))

n <- nPatients/2
m <- nPatients

#JAGS code which calculates posterior distributions

modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1, 1)T(0,)
    HR ~ dnorm(0.75, 40)T(0,)
    bigT ~ dnorm(3, 1/bigTsd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = IAData$time, datEvent = IAData$status, bigTsd = bigTsd, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT"), n.iter = 500)

HROutput <- as.numeric(output[[1]][,1])

HRVec[j] <- mean(HROutput<1)
}

return(HRVec)
}



```

```{r}
x0.001 <- bigTFunc(bigTsd = 0.001)
x0.01 <- bigTFunc(bigTsd = 0.01)
x0.1 <- bigTFunc(bigTsd = 0.1)
x1 <- bigTFunc(bigTsd = 1)

```

```{r}
hist(x0.001, xlim=c(0,1), ylim=c(0,25))
hist(x0.01, xlim=c(0,1), ylim=c(0,25))
hist(x0.1, xlim=c(0,1), ylim=c(0,25))
hist(x1, xlim=c(0,1), ylim=c(0,25))

mean(x0.001)
mean(x0.01)
mean(x0.1)
mean(x1)
```

```{r, eval = F}

myFunc <- function(bigTsd){
  lambdac <- -log(0.5)/12
nEvents <- 512
nPatients <- 680
recTime <- 34
assvec <- rep(NA, 100)
sampledHR <- rep(NA, 100)
observedHR <- rep(NA, 100)

for (i in 1:length(assvec)){
  
  HR <- rnorm(1, mean = 0.75, sd = 0.05)
  sampledHR[i] <- HR
bigT <- truncnorm::rtruncnorm(n = 1, a = 0,  mean = 3, sd = bigTsd)
lambdat  <- lambdac*HR
  
  CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]

  samplevec <- sample(1:nPatients)

  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  observedHR[i] <- as.numeric(exp(coef(coxmodel)))
  
  #Look at a futility stop 50% the way through the events
  
  IAData1 <- combinedData
  
  IATime1  <- IAData1[nEvents*0.5,]$time
  
  IAData1$status <- IAData1$time<=IATime1
  
  IAData1[IAData1$status==F,]$time <- IATime1
  
  IAData1 <- IAData1[order(IAData1$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IAData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    assvec[i] <- 1
  } else {
    
  IAData2 <- combinedData
  
  IATime2  <- IAData2[nEvents*0.75,]$time
  
  IAData2$status <- IAData2$time<=IATime2
  
  IAData2[IAData2$status==F,]$time <- IATime2
  
  IAData2 <- IAData1[order(IAData2$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IAData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    assvec[i] <- 2
  } else {
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (test$chisq>qchisq(0.95, 1)&deltad<1){
    assvec[i] <- 4
  } else{
    assvec[i] <- 3
  }
    
    
  }
  }
}
mydf <- data.frame(StopFirstLook = mean(assvec==1), StopSecondLook = mean(assvec==2),
                   NotSignifFinal = mean(assvec==3), SignifFinal = mean(assvec==4))

return(list(mydf = mydf, sampledHR = sampledHR, observedHR = observedHR))
}


```

```{r, eval = F}

output <- myFunc(1)

plot(output$sampledHR, output$observedHR, xlim=c(0.5, 1.2), ylim=c(0.5, 1.2))

# myFunc(0.5)
# 
# myFunc(1)
```

How does changing the prior for T affect the futility/power?

```{r, echo=F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 1e3
assvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(3, 0^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0))
```


$T \sim N(3, 0.0001^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.0001))
```

$T \sim N(3, 0.001^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.001))
```

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

$T \sim N(3, 0.1^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.1))
```

$T \sim N(3, 1^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 1))
```


Does the posterior for HR look any different when we accept/reject for futility at the IA?

```{r}
library(rjags)
  HRMean <- 1
  HRsd <- 0.1
  lengthDelayMean <- 3
  lengthDelaysd <- 0.1
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 50
assvec <- rep(NA, nSims)
MeanHR <- rep(NA, nSims)


for (i in 1:nSims){
  
  
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(n = 1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  IACombinedData1 <- IACombinedData1[order(IACombinedData1$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
   assvec[i] <- 1
  } else {
    assvec[i] <- 2
  }

  n <- nPatients/2
m <- nPatients

#JAGS code which calculates posterior distributions

modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1, 1)T(0,)
    HR ~ dnorm(0.75, 40)T(0,)
    bigT ~ dnorm(3, 1/lengthDelaysd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = IACombinedData1$time, datEvent = IACombinedData1$status, lengthDelaysd = lengthDelaysd, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT"), n.iter = 500)

#plot(output)

HRMean[i] <- mean(as.numeric(output[[1]][,1]))

}


```


Let us do Bayesian updating at the interim analysis - for the same case study

What is the assurance before the trial?

```{r}
HRMean <- 0.75
HRsd <- 0.1
lengthDelayMean <- 3
lengthDelaysd <- 1
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12


assvec <- rep(NA, 1000)

for (i in 1:1000){
  
  lengthDelay <- truncnorm::rtruncnorm(n = 1, a = 0, mean = lengthDelayMean, sd = lengthDelaysd)
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
  lambdat <- lambdac*HR

  
CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
}

mean(assvec)
```


We need to simulate some data

```{r}
HRMean <- 0.75
HRsd <- 0.1
lengthDelayMean <- 3
lengthDelaysd <- 1
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

lengthDelay <- truncnorm::rtruncnorm(n = 1, a = 0, mean = lengthDelayMean, sd = lengthDelaysd)
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
  lambdat <- lambdac*HR
  
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  
  enrollment_times <- rpois(nPatients, 10)
  
  
  
  
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  


```


```{r}



# HRMean <- 0.75
# HRsd <- 0.1
# lengthDelayMean <- 3
# lengthDelaysd <- 1
nEvents <- 512
nPatients <- 680
# recTime <- 34
lambdac <- -log(0.5)/12

# lengthDelay <- truncnorm::rtruncnorm(n = 1, a = 0, mean = lengthDelayMean, sd = lengthDelaysd)
#   HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
#   lambdat <- lambdac*HR


lengthDelay <- 0
HR <- 0.75
lambdat <- lambdac*HR



CP <- exp(-(lambdac*lengthDelay))
u <- runif(nPatients/2)
  
survivalTimes <- c(rexp(nPatients/2), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac)))
  

group = c(rep("Control", nPatients/2), rep("Treatment", nPatients/2))

enrollment_times <- rep(NA,  nPatients)

for (k in 1:nPatients){
    enrollment_times[k] <- runif(1, min = floor(k/20), max = ceiling(k/20))
}

enrollment_times <- sample(enrollment_times)


pseudo_surv <- survivalTimes + enrollment_times

 censTime <- sort(pseudo_surv)[nEvents]
 
 enrolled <- ifelse(enrollment_times<censTime, 1, 0)
 
 newSurvTime <- ifelse(pseudo_surv>censTime, censTime - enrollment_times, survivalTimes)
 
 censor <- ifelse(pseudo_surv>censTime, 0, 1)
 
 finalDF <- data.frame(newSurvTime, censor, group, enrolled)
 
 finalDF <- finalDF[finalDF[,4]==1,]
 
 sum(finalDF$censor==1)

```


```{r}
#PHM
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTimeVec <- rep(NA, nPatients)
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

powervec <- rep(NA, 1000)
censvec <- rep(NA, 1000)

 for (i in 1:1000){
  

  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), rexp(nPatients/2, rate = lambdat)), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData$recTime <- runif(nPatients, min = 0, max = 34)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents]
  
  combinedData$status <- combinedData$psuedoTime < censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime < censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
 test <- survdiff(Surv(survival_time, status)~group, data = combinedData)
  
powervec[i] <- test$chisq > qchisq(0.95, 1)
censvec[i] <- censTime
}
 
mean(powervec)
median(censvec)
```

```{r}
#DTE
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTimeVec <- rep(NA, nPatients)
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

powervec <- rep(NA, 1000)
censvec <- rep(NA, 1000)

 for (i in 1:1000){
  

  CP <- exp(-(lambdac*3))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(3*lambdat-log(u)-3*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  

  combinedData$recTime <- runif(nPatients, min = 0, max = 34)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents]
  
  combinedData$status <- combinedData$psuedoTime <= censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime <= censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
 test <- survdiff(Surv(survival_time, status)~group, data = combinedData)
  
powervec[i] <- test$chisq > qchisq(0.95, 1)
censvec[i] <- censTime
}
 
mean(powervec)
median(censvec)
```

We put some priors on the T and post-delay HR

```{r}
#DTE assurance
nEvents <- 512
nPatients <- 680
recTimeVec <- rep(NA, nPatients)
lambdac <- -log(0.5)/12
recTime <- 34


powervec <- rep(NA, 1000)
censvec <- rep(NA, 1000)

 for (i in 1:1000){
  
   
  bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = 1)
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 0.75, sd = 0.1)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*bigT))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  

  combinedData$recTime <- runif(nPatients, min = 0, max = recTime)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents]
  
  combinedData$status <- combinedData$psuedoTime <= censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime <= censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
 test <- survdiff(Surv(survival_time, status)~group, data = combinedData)
  
powervec[i] <- test$chisq > qchisq(0.95, 1)
censvec[i] <- censTime
}
 
mean(powervec)
median(censvec)
```

So we have that the prior assurance is approximately 65%. 
Can we update this at any interim point?
We choose 50% IF - so when 256 events have been observed

```{r}
library(rjags)
library(survival)
library(tidyverse)

for (k in 1:100){
  print(k)

nEvents <- 512
nPatients <- 680
lambdac <- -log(0.5)/12
recTime <- 34
WieandOutcome <- ""
OBFOutcome <- ""
PropOutcome <- ""

#bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = 1)
#HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 0.75, sd = 0.1)
bigT <- 3
HR <- 0.55
lambdat <- lambdac*HR

CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)

overallFinalData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))

  overallFinalData$recTime <- runif(nPatients, min = 0, max = recTime)
  
  overallFinalData$psuedoTime <- overallFinalData$time + overallFinalData$recTime
  
  #We create a function which allows us to choose at what point we censor the data
  
  censorFunc <- function(censorEvents){
    
    censorData <- overallFinalData
    
    censTime <- sort(censorData$psuedoTime)[censorEvents]
    
    censorData$status <- censorData$psuedoTime <= censTime
    
    censorData$status <- censorData$status*1
    
    censorData$enrolled <- censorData$recTime <= censTime
    
    censorData <-  censorData[censorData$enrolled==T,]
    
    censorData$survival_time <- ifelse(censorData$psuedoTime>censTime, censTime  - censorData$recTime, censorData$time)
    
    coxmodel <- coxph(Surv(survival_time, status)~group, data = censorData)
    
    deltad <- as.numeric(exp(coef(coxmodel)))
    
    test <- survdiff(Surv(survival_time, status)~group, data = censorData)
    
    return(list(censorData = censorData, censTime = censTime, deltad = deltad, test = test))
    
  }
  
  #Calculating how many events we need to observe for the proposed futility rule
  
  propvec <- rep(NA, nEvents/2)
  
  for (i in (nEvents*0.5):nEvents){
    
    IAData <- overallFinalData
    censTime1 <- sort(IAData$psuedoTime)[i]
    IAData$status <- IAData$psuedoTime <= censTime1
    IAData$status <- IAData$status*1
    IAData$enrolled <- IAData$recTime <= censTime1
    IAData <-  IAData[IAData$enrolled==T,]
    IAData$survival_time <- ifelse(IAData$psuedoTime>censTime1, censTime1  - IAData$recTime, IAData$time)
  
    IAData <- IAData %>%
      filter(status==1)  

    propvec[i-(nEvents/2)] <- mean(IAData$survival_time>3)
  }
    
  nEventsIA1 <- max(sum(propvec<(2/3))+nEvents/2, nEvents*0.5)
  
  nEventsIA2 <- max(sum(propvec<(2/3))+nEvents/2, nEvents*0.75)

  
  #We perform the Wieand rule
  
  
  if (censorFunc(nEvents*0.5)$deltad>1){
    WieandOutcome <- "Stop for futility at IA1"
  } else {
  
     if (censorFunc(nEvents*0.75)$deltad>1){
      WieandOutcome <- "Stop for futility at IA2"
    } else {
      
      if (censorFunc(nEvents)$test$chisq > qchisq(0.95, 1) & censorFunc(nEvents)$deltad<1){
        WieandOutcome <- "Successful trial (at the end)"
      } else {
         WieandOutcome <- "Not a successful trial (at the end)"
      }
    }
  }
  
  
  #We perform the OBF rule
  
   
  if (censorFunc(nEvents*(1/3))$deltad>0.998){
    OBFOutcome <- "Stop for futility at IA1"
  } else {
  
     if (censorFunc(nEvents*(2/3))$deltad>0.913){
      OBFOutcome <- "Stop for futility at IA2"
    } else {
      
      if (censorFunc(nEvents)$test$chisq > qchisq(0.95, 1) & censorFunc(nEvents)$deltad<1){
        OBFOutcome <- "Successful trial (at the end)"
      } else {
         OBFOutcome <- "Not a successful trial (at the end)"
      }
    }
  }
  
  #We perform the proposed rule
  
   if (censorFunc(nEventsIA1)$deltad>1){
    PropOutcome <- "Stop for futility at IA1"
  } else {
  
     if (censorFunc(nEventsIA2)$deltad>1){
      PropOutcome <- "Stop for futility at IA2"
    } else {
      
      if (censorFunc(nEvents)$test$chisq > qchisq(0.95, 1) & censorFunc(nEvents)$deltad<1){
        PropOutcome <- "Successful trial (at the end)"
      } else {
         PropOutcome <- "Not a successful trial (at the end)"
      }
    }
  }
  

  #A function which calculates BPP given the interim data and the time of censoring
  
  BPPFunc <- function(IAData, censTime){
  
  n <- sum(IAData$group=="Control")
  m <- nrow(IAData)
  
  IAData <- IAData[order(IAData$group),]
  
  IAkmfit <- survfit(Surv(survival_time, status)~group, data = IAData) 
  
  #plot(IAkmfit, col = c("blue", "red"), xlim=c(0,50))
  
 

  #We need to update the priors using this interim data
  modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1,1)
    HR ~ dnorm(0.75, 1/HRsd)T(0,)
    bigT ~ dnorm(3, 1/bigTsd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = IAData$survival_time, datEvent = IAData$status, bigTsd = 1, HRsd = 0.1, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT", "lambda2"), n.iter = 500)
  
#plot(output)

  #The number of unenrolled patients in each group
  cPatientsLeft <- (nPatients/2) - sum(IAData$group=="Control") 
  tPatientsLeft <- (nPatients/2) - sum(IAData$group=="Treatment") 
  
  BPPVec <- rep(NA, 500)
  
  for (i in 1:500){
    
  #Sampling the recruitment times for the unenrolled patients
  unenrolledRecTimes <- runif(cPatientsLeft+tPatientsLeft, censTime, recTime)
  
  #Extract realisations from the MCMC
  HRoutput <- as.numeric(unlist(output[,1]))
  bigToutput <- as.numeric(unlist(output[,2]))
  lambda2output <- as.numeric(unlist(output[,3]))
  
  #Sample values from the MCMC output
  sampledHR <- sample(HRoutput, 1)
  sampledbigT <- sample(bigToutput, 1)
  sampledlambda2 <- sample(lambda2output, 1)
  sampledlambda1 <- sampledlambda2*sampledHR
  
  
  #For the unenrolled data, we can sample the remaining data according to the updated (sampled) parameters
  CP <- exp(-(sampledlambda2*sampledbigT))
  u <- runif(tPatientsLeft)

unenrolledData <- data.frame(time = c(rexp(cPatientsLeft, rate = sampledlambda2), ifelse(u>CP, (-log(u))/sampledlambda2, (1/sampledlambda1)*(sampledbigT*sampledlambda1-log(u)-sampledbigT*sampledlambda2))), group = c(rep("Control", cPatientsLeft),
                             rep("Treatment", tPatientsLeft)), recTime = unenrolledRecTimes)

unenrolledData$psuedoTime <- unenrolledData$time + unenrolledData$recTime


#Extracting the observations that were censored at the IA  
censoredData <- IAData[IAData$status==0,]

#Number of censored observations in each group
cCensored <- sum(censoredData$group=="Control")
tCensored <- sum(censoredData$group=="Treatment")

#Extracting the censored observations in the control group
cCensoredData <- censoredData %>%
  filter(group=="Control")

#Adding a exp(sampledlambda2) value to the censored value
cCensoredData$finalsurvTime <- cCensoredData$survival_time + rexp(cCensored, rate = sampledlambda2)

#Calculating the psuedo time
cCensoredData$finalPsuedoTime <- cCensoredData$recTime + cCensoredData$finalsurvTime

#Extacting the observations in the treatment group which may still be influenced by the delay (their observation time is smaller than the sampled delay time)
tBeforeDelay <- censoredData %>%
  filter(group=="Treatment") %>%
  filter(survival_time < sampledbigT)

#Extracting the observations in the treatment group which will not be influenced by the delay (their observation time is bigger than the sampled delay time)
tAfterDelay <- censoredData %>%
  filter(group=="Treatment") %>%
  filter(survival_time > sampledbigT)

#As these observations are still subject to a delay, we add on a Exp(lambda2) (lambdac) time
tBeforeDelay$IASurv <- tBeforeDelay$survival_time + rexp(nrow(tBeforeDelay), rate = sampledlambda2)

#Extracting the observations in which the survival time is smaller than the sampled delay time
tBeforeDelay1 <- tBeforeDelay %>%
  filter(IASurv < sampledbigT)

#Extracting the observations in which the survival time is bigger than the sampled delay time
tBeforeDelay2 <- tBeforeDelay %>%
  filter(IASurv > sampledbigT)

#For the observations in which the survival time is bigger, we sample a Exp(lambda1) and add it to the sampled delay time
tBeforeDelay2$IASurv2 <- sampledbigT + rexp(nrow(tBeforeDelay2), rate = sampledlambda1)

#For the observations not influenced by the delay, we sample a Exp(lambda1) time and add it to the current survival time
tAfterDelay$IASurv <- tAfterDelay$survival_time + rexp(nrow(tAfterDelay), rate = sampledlambda1)

#Calculate the pseudo time for all the data frames
tBeforeDelay1$IApsuedoTime <- tBeforeDelay1$IASurv + tBeforeDelay1$recTime
tBeforeDelay2$IApsuedoTime <- tBeforeDelay2$IASurv2 + tBeforeDelay2$recTime
tAfterDelay$IApsuedoTime <- tAfterDelay$IASurv + tAfterDelay$recTime

#Only keeping the columns of interest
cCensoredData <- cCensoredData[,c(2:3, 8:9)]
tBeforeDelay1 <- tBeforeDelay1[,c(2:3, 8:9)]
tBeforeDelay2 <- tBeforeDelay2[,c(2:3, 9:10)]
tAfterDelay <- tAfterDelay[,c(2:3, 8:9)]

#Keeping the column names consistent
colnames(cCensoredData) <- c("group", "recTime", "time", "psuedoTime")
colnames(tBeforeDelay1) <- c("group", "recTime", "time", "psuedoTime")
colnames(tBeforeDelay2) <- c("group", "recTime", "time", "psuedoTime")
colnames(tAfterDelay) <- c("group", "recTime", "time", "psuedoTime")

#Only keeping observations which are dead
finalDataset <- IAData %>%
  filter(status==1)

finalDataset <- finalDataset[,1:4]

#Combining all the above data sets 
finalDataset <- rbind(finalDataset, tBeforeDelay1)
finalDataset <- rbind(finalDataset, tBeforeDelay2)
finalDataset <- rbind(finalDataset, tAfterDelay)
finalDataset <- rbind(finalDataset, unenrolledData)
finalDataset <- rbind(finalDataset, cCensoredData)

#Making sure the final data set is correct
censTime1 <- sort(finalDataset$psuedoTime)[nEvents]
finalDataset$status <- finalDataset$psuedoTime <= censTime1
finalDataset$status <- finalDataset$status*1
finalDataset$enrolled <- finalDataset$recTime <= censTime1
finalDataset <-  finalDataset[finalDataset$enrolled==T,]
finalDataset$survival_time <- ifelse(finalDataset$psuedoTime>censTime1, censTime1  - finalDataset$recTime, finalDataset$time)

#Testing for significance
test <- survdiff(Surv(survival_time, status)~group, data = finalDataset)
   
#kmfit <- survfit(Surv(survival_time, status)~group, data = finalDataset)
#plot(kmfit, col = c("blue", "red"), xlim=c(0,50))

#Making sure the significance is in the correct direction
coxmodel <- coxph(Surv(survival_time, status)~group, data = finalDataset)
deltad <- as.numeric(exp(coef(coxmodel)))

   
 BPPVec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
   
  }
   

return(BPP = mean(BPPVec))
  }
  
  

#wieand rule BPP

WBPP1 <- BPPFunc(censorFunc(nEvents*0.5)$censorData, censorFunc(nEvents*0.5)$censTime)
WBPP2 <- BPPFunc(censorFunc(nEvents*0.75)$censorData, censorFunc(nEvents*0.75)$censTime)

#OBF rule BPP

OBFBPP1 <- BPPFunc(censorFunc(nEvents*(1/3))$censorData, censorFunc(nEvents*(1/3))$censTime)
OBFBPP2 <- BPPFunc(censorFunc(nEvents*(2/3))$censorData, censorFunc(nEvents*(2/3))$censTime)

#Proposed rule BPP

PropBPP1 <- BPPFunc(censorFunc(nEventsIA1)$censorData, censorFunc(nEventsIA1)$censTime)
PropBPP2 <- BPPFunc(censorFunc(nEventsIA2)$censorData, censorFunc(nEventsIA2)$censTime)

if (k==1){
  outcomeDF <- data.frame(WieandOutcome = WieandOutcome, OBFOutcome = OBFOutcome, PropOutcome = PropOutcome, WBPP1 = WBPP1, WBPP2 = WBPP2,
           OBFBPP1 = OBFBPP1, OBFBPP2 = OBFBPP2, PropBPP1 = PropBPP1, PropBPP2 = PropBPP2,
           nEventsIA1 = nEventsIA1, nEventsIA2 = nEventsIA2)
} else {
  currentDF <- data.frame(WieandOutcome = WieandOutcome, OBFOutcome = OBFOutcome, PropOutcome = PropOutcome, WBPP1 = WBPP1, WBPP2 = WBPP2,
           OBFBPP1 = OBFBPP1, OBFBPP2 = OBFBPP2, PropBPP1 = PropBPP1, PropBPP2 = PropBPP2, nEventsIA1 = nEventsIA1, nEventsIA2 = nEventsIA2)
  outcomeDF <- rbind(outcomeDF, currentDF)
}

}


```

```{r}
nEvents <- 512
nPatients <- 680
lambdac <- -log(0.5)/12
recTime <- 12


bigT <- 3
HR <- 1
lambdat <- lambdac*HR

CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)

overallFinalData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))

  overallFinalData$recTime <- runif(nPatients, min = 0, max = recTime)
  
  overallFinalData$psuedoTime <- overallFinalData$time + overallFinalData$recTime
  
  propvec <- rep(NA, nEvents/2)
  for (i in (nEvents*0.5):nEvents){
    
    IAData <- overallFinalData
      
  censTime1 <- sort(IAData$psuedoTime)[i]
IAData$status <- IAData$psuedoTime <= censTime1
IAData$status <- IAData$status*1
IAData$enrolled <- IAData$recTime <= censTime1
IAData <-  IAData[IAData$enrolled==T,]
IAData$survival_time <- ifelse(IAData$psuedoTime>censTime1, censTime1  - IAData$recTime, IAData$time)
  
IAData <- IAData %>%
  filter(status==1)  

propvec[i-(nEvents/2)] <- mean(IAData$survival_time>3)
  }
    
  nEventsIA1 <- max(sum(propvec<(2/3))+nEvents/2, nEvents*0.5)
  
  nEventsIA2 <- max(sum(propvec<(2/3))+nEvents/2, nEvents*0.75)
  
  nEventsIA1
  nEventsIA2
  

```



```{r}

nEvents <- 6600
nPatients <- 6800
lambdac <- -log(0.5)/12
recTime <- 34



combinedData <- data.frame(time = c(rexp(nPatients, rate = lambdac)))

combinedData$recTime <- runif(nPatients, min = 0, max = recTime)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censVec <- seq(0.2, 1, by=0.2)
  
  #for (i in 1:5){
    
  IAData <- combinedData
    
  censTime <- sort(IAData$psuedoTime)[nEvents*0.2]
  
  IAData$status <- IAData$psuedoTime <= censTime
  
  IAData$status <- IAData$status*1
  
  IAData$enrolled <- IAData$recTime <= censTime
  
  IAData <-  IAData[IAData$enrolled==T,]
  
  IAData$survival_time <- ifelse(IAData$psuedoTime>censTime, censTime  - IAData$recTime, IAData$time)
  
  controlkm <- survfit(Surv(survival_time, status)~1, data = IAData)
  
  #plot(controlkm, conf.int = F, col = "blue", xlim=c(0,100))
  
  controltime <- seq(0, 100, by=0.01)
  
  controlsurv <- exp(-lambdac*controltime)
  
  lines(controltime, controlsurv)
  
  #Try and recover the "true line"
  
  #Patients who have not yet been enrolled in the trial
  
  #How many patients are there 
  
  nNotYetEnrolled <- nPatients - nrow(IAData)
  
  notYetEnrolled <- data.frame(time = rexp(nNotYetEnrolled, rate = lambdac), recTime = runif(nNotYetEnrolled, censTime, recTime))
  
  notYetEnrolled$psuedoTime <- notYetEnrolled$time + notYetEnrolled$recTime
  
 finalData <- IAData %>%
    filter(status==1)
  
  finalData <- finalData[,1:3]
  
  finalData <- rbind(finalData, notYetEnrolled)
  
  censoredData <- IAData %>%
    filter(status==0)
  
  censoredData$finalsurvTime <- censoredData$survival_time + rexp(nrow(censoredData), rate = lambdac)
  
  censoredData$finalPsuedoTime <- censoredData$recTime + censoredData$finalsurvTime
  
  
  censoredData <- censoredData[,c(2, 7:8)]
 
  
  colnames(censoredData) <- c("recTime", "time", "psuedoTime") 
  
  finalData <- rbind(finalData, censoredData)
  
  censTime <- sort(finalData$psuedoTime)[nEvents]
  
  finalData$status <- finalData$psuedoTime <= censTime
  
  finalData$status <- finalData$status*1
  
  finalData$enrolled <- finalData$recTime <= censTime
  
  finalData <-  finalData[finalData$enrolled==T,]
  
  finalData$survival_time <- ifelse(finalData$psuedoTime>censTime, censTime  - finalData$recTime, finalData$time)
  
  controlkm <- survfit(Surv(survival_time, status)~1, data = finalData)
  
  plot(controlkm, conf.int = F, col = "blue", xlim=c(0,100))
  
  controltime <- seq(0, 100, by=0.01)
  
  controlsurv <- exp(-lambdac*controltime)
  
  lines(controltime, controlsurv)
  
  
    
 # }
  
  

```






