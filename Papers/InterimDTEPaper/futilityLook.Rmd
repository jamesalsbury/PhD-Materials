---
title: "futilityLook"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(truncnorm)
```

We are looking at including futility looks into the clinical trial. We recreate the results from [Korn and Freidlin (2018)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6366306/pdf/JCO.2018.77.7144.pdf). We have the following setup:
We require 512 events, a sample size of 680. We assume the hazard ratio is 0.75, we have uniform recruitment for 34 months. We have exponential survival in the control arm, with a median survival of 12 months. We introduce three futility rules:

1) Wieand rule
* At 50% information, stop if the observed HR > 1
* At 75% information, stop if the observed HR > 1

2) O'Brien-Fleming $\beta$ spending
* At 33% information, stop if the observed HR > 0.998
* At 67% information, stop if the observed HR > 0.913

3) Proposed rule - by Korn and Freidlin
* At 50% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1
* At 75% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1

```{r, echo=F, eval = F}
futilityPowerFunc <- function(HR, lengthDelay){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

nSims <- 1e3
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  powervec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```
These are the results seen when HR is 0.75 and there is no delay

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 0))
```

These are the results seen when HR is 0.75 and there is a delay of 3 months

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 3))
```

These are the results seen when HR is 0.75 and there is a delay of 6 months

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 6))
```

These are the results seen when HR is 1 (and no delay)

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 1, lengthDelay = 0))
```

These are the results seen when HR is 1.3 (and no delay)

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 1.3, lengthDelay = 0))
```

# Assurance

We can add some uncertainty to the parameters to see if this makes a difference to the calculations shown for futility

```{r, echo=F, eval = F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 1e3
assvec <- rep(NA, nSims)
Wieandassvec <- rep(NA, nSims)
OBFassvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandassvec[i] <- 4
    } else {
      Wieandassvec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFassvec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFassvec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFassvec[i] <- 4
    } else {
      OBFassvec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Wieand = c(mean(Wieandassvec==4), mean(Wieandcensvec)), OBF = c(mean(OBFassvec==4), mean(OBFcensvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(0, 0^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 0, lengthDelaysd = 0))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.01^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.01, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(6, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 6, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(1, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 1, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

# Doing the Bayesian updating at the interim

We need to find a way of updating the prior distributions at any interim analysis


```{r, eval = F}
library(rjags)

bigTFunc <- function(bigTsd){
  HRVec <- rep(NA, 100)

for (j in 1:100){
  HR <- rnorm(1, mean = 0.75, sd = 0.05)
bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = bigTsd)
lambdac <- -log(0.5)/12
lambdat  <- lambdac*HR
nEvents <- 512
nPatients <- 680
recTime <- 34

CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]

  samplevec <- sample(1:nPatients)

  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #Look at a futility stop 50% the way through the events
  
  IAData <- combinedData
  
  IATime  <- IAData[nEvents*0.5,]$time
  
  IAData$status <- IAData$time<=IATime
  
  IAData[IAData$status==F,]$time <- IATime
  
  IAData <- IAData[order(IAData$group),]

  controlkm <- survfit(Surv(time, status)~group, data = IAData)
# 
#plot(controlkm, col=c("blue", "red"))

#legend("topright", legend = c("Control", "Treatment"), col = c("blue", "red"), lty=1)

 coxmodel <- coxph(Surv(time, status)~group, data = IAData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))

n <- nPatients/2
m <- nPatients

#JAGS code which calculates posterior distributions

modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1, 1)T(0,)
    HR ~ dnorm(0.75, 40)T(0,)
    bigT ~ dnorm(3, 1/bigTsd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = IAData$time, datEvent = IAData$status, bigTsd = bigTsd, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT"), n.iter = 500)

HROutput <- as.numeric(output[[1]][,1])

HRVec[j] <- mean(HROutput<1)
}

return(HRVec)
}



```

```{r}
x0.001 <- bigTFunc(bigTsd = 0.001)
x0.01 <- bigTFunc(bigTsd = 0.01)
x0.1 <- bigTFunc(bigTsd = 0.1)
x1 <- bigTFunc(bigTsd = 1)

```

```{r}
hist(x0.001, xlim=c(0,1), ylim=c(0,25))
hist(x0.01, xlim=c(0,1), ylim=c(0,25))
hist(x0.1, xlim=c(0,1), ylim=c(0,25))
hist(x1, xlim=c(0,1), ylim=c(0,25))

mean(x0.001)
mean(x0.01)
mean(x0.1)
mean(x1)
```

```{r, eval = F}

myFunc <- function(bigTsd){
  lambdac <- -log(0.5)/12
nEvents <- 512
nPatients <- 680
recTime <- 34
assvec <- rep(NA, 100)
sampledHR <- rep(NA, 100)
observedHR <- rep(NA, 100)

for (i in 1:length(assvec)){
  
  HR <- rnorm(1, mean = 0.75, sd = 0.05)
  sampledHR[i] <- HR
bigT <- truncnorm::rtruncnorm(n = 1, a = 0,  mean = 3, sd = bigTsd)
lambdat  <- lambdac*HR
  
  CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]

  samplevec <- sample(1:nPatients)

  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  observedHR[i] <- as.numeric(exp(coef(coxmodel)))
  
  #Look at a futility stop 50% the way through the events
  
  IAData1 <- combinedData
  
  IATime1  <- IAData1[nEvents*0.5,]$time
  
  IAData1$status <- IAData1$time<=IATime1
  
  IAData1[IAData1$status==F,]$time <- IATime1
  
  IAData1 <- IAData1[order(IAData1$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IAData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    assvec[i] <- 1
  } else {
    
  IAData2 <- combinedData
  
  IATime2  <- IAData2[nEvents*0.75,]$time
  
  IAData2$status <- IAData2$time<=IATime2
  
  IAData2[IAData2$status==F,]$time <- IATime2
  
  IAData2 <- IAData1[order(IAData2$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IAData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    assvec[i] <- 2
  } else {
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (test$chisq>qchisq(0.95, 1)&deltad<1){
    assvec[i] <- 4
  } else{
    assvec[i] <- 3
  }
    
    
  }
  }
}
mydf <- data.frame(StopFirstLook = mean(assvec==1), StopSecondLook = mean(assvec==2),
                   NotSignifFinal = mean(assvec==3), SignifFinal = mean(assvec==4))

return(list(mydf = mydf, sampledHR = sampledHR, observedHR = observedHR))
}


```

```{r, eval = F}

output <- myFunc(1)

plot(output$sampledHR, output$observedHR, xlim=c(0.5, 1.2), ylim=c(0.5, 1.2))

# myFunc(0.5)
# 
# myFunc(1)
```

How does changing the prior for T affect the futility/power?

```{r, echo=F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 1e3
assvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(3, 0^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0))
```


$T \sim N(3, 0.0001^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.0001))
```

$T \sim N(3, 0.001^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.001))
```

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

$T \sim N(3, 0.1^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.1))
```

$T \sim N(3, 1^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 1))
```


Does the posterior for HR look any different when we accept/reject for futility at the IA?

```{r}
library(rjags)
  HRMean <- 1
  HRsd <- 0.1
  lengthDelayMean <- 3
  lengthDelaysd <- 0.1
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 50
assvec <- rep(NA, nSims)
MeanHR <- rep(NA, nSims)


for (i in 1:nSims){
  
  
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(n = 1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  IACombinedData1 <- IACombinedData1[order(IACombinedData1$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
   assvec[i] <- 1
  } else {
    assvec[i] <- 2
  }

  n <- nPatients/2
m <- nPatients

#JAGS code which calculates posterior distributions

modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1, 1)T(0,)
    HR ~ dnorm(0.75, 40)T(0,)
    bigT ~ dnorm(3, 1/lengthDelaysd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = IACombinedData1$time, datEvent = IACombinedData1$status, lengthDelaysd = lengthDelaysd, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT"), n.iter = 500)

#plot(output)

HRMean[i] <- mean(as.numeric(output[[1]][,1]))

}


```


Let us do Bayesian updating at the interim analysis - for the same case study

What is the assurance before the trial?

```{r}
HRMean <- 0.75
HRsd <- 0.1
lengthDelayMean <- 3
lengthDelaysd <- 1
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12


assvec <- rep(NA, 1000)

for (i in 1:1000){
  
  lengthDelay <- truncnorm::rtruncnorm(n = 1, a = 0, mean = lengthDelayMean, sd = lengthDelaysd)
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
  lambdat <- lambdac*HR

  
CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
}

mean(assvec)
```


We need to simulate some data

```{r}
HRMean <- 0.75
HRsd <- 0.1
lengthDelayMean <- 3
lengthDelaysd <- 1
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

lengthDelay <- truncnorm::rtruncnorm(n = 1, a = 0, mean = lengthDelayMean, sd = lengthDelaysd)
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
  lambdat <- lambdac*HR
  
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  
  enrollment_times <- rpois(nPatients, 10)
  
  
  
  
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  


```


```{r}



# HRMean <- 0.75
# HRsd <- 0.1
# lengthDelayMean <- 3
# lengthDelaysd <- 1
nEvents <- 512
nPatients <- 680
# recTime <- 34
lambdac <- -log(0.5)/12

# lengthDelay <- truncnorm::rtruncnorm(n = 1, a = 0, mean = lengthDelayMean, sd = lengthDelaysd)
#   HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = HRMean, sd = HRsd)
#   lambdat <- lambdac*HR


lengthDelay <- 0
HR <- 0.75
lambdat <- lambdac*HR



CP <- exp(-(lambdac*lengthDelay))
u <- runif(nPatients/2)
  
survivalTimes <- c(rexp(nPatients/2), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac)))
  

group = c(rep("Control", nPatients/2), rep("Treatment", nPatients/2))

enrollment_times <- rep(NA,  nPatients)

for (k in 1:nPatients){
    enrollment_times[k] <- runif(1, min = floor(k/20), max = ceiling(k/20))
}

enrollment_times <- sample(enrollment_times)


pseudo_surv <- survivalTimes + enrollment_times

 censTime <- sort(pseudo_surv)[nEvents]
 
 enrolled <- ifelse(enrollment_times<censTime, 1, 0)
 
 newSurvTime <- ifelse(pseudo_surv>censTime, censTime - enrollment_times, survivalTimes)
 
 censor <- ifelse(pseudo_surv>censTime, 0, 1)
 
 finalDF <- data.frame(newSurvTime, censor, group, enrolled)
 
 finalDF <- finalDF[finalDF[,4]==1,]
 
 sum(finalDF$censor==1)

```


```{r}
#PHM
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTimeVec <- rep(NA, nPatients)
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

powervec <- rep(NA, 1000)
censvec <- rep(NA, 1000)

 for (i in 1:1000){
  

  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), rexp(nPatients/2, rate = lambdat)), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData$recTime <- runif(nPatients, min = 0, max = 34)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents]
  
  combinedData$status <- combinedData$psuedoTime < censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime < censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
 test <- survdiff(Surv(survival_time, status)~group, data = combinedData)
  
powervec[i] <- test$chisq > qchisq(0.95, 1)
censvec[i] <- censTime
}
 
mean(powervec)
median(censvec)
```

```{r}
#DTE
nEvents <- 512
nPatients <- 680
HR <- 0.75
recTimeVec <- rep(NA, nPatients)
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

powervec <- rep(NA, 1000)
censvec <- rep(NA, 1000)

 for (i in 1:1000){
  

  CP <- exp(-(lambdac*3))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(3*lambdat-log(u)-3*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  

  combinedData$recTime <- runif(nPatients, min = 0, max = 34)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents]
  
  combinedData$status <- combinedData$psuedoTime <= censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime <= censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
 test <- survdiff(Surv(survival_time, status)~group, data = combinedData)
  
powervec[i] <- test$chisq > qchisq(0.95, 1)
censvec[i] <- censTime
}
 
mean(powervec)
median(censvec)
```

We put some priors on the T and post-delay HR

```{r}
#DTE assurance
nEvents <- 512
nPatients <- 680
recTimeVec <- rep(NA, nPatients)
lambdac <- -log(0.5)/12
recTime <- 34


powervec <- rep(NA, 10000)
censvec <- rep(NA, 10000)

 for (i in 1:10000){
  
   
  bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = 1)
  HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 0.75, sd = 0.1)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*bigT))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  

  combinedData$recTime <- runif(nPatients, min = 0, max = recTime)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents]
  
  combinedData$status <- combinedData$psuedoTime <= censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime <= censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
 test <- survdiff(Surv(survival_time, status)~group, data = combinedData)
  
powervec[i] <- test$chisq > qchisq(0.95, 1)
censvec[i] <- censTime
}
 
mean(powervec)
median(censvec)
```

So we have that the prior assurance is approximately 65%. 
Can we update this at any interim point?
We choose 50% IF - so when 256 events have been observed

```{r}
library(rjags)
library(survival)
library(tidyverse)
nEvents <- 512
nPatients <- 680
lambdac <- -log(0.5)/12
recTime <- 34

bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = 1)
HR <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 0.75, sd = 0.1)
lambdat <- lambdac*HR

CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)

combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))

combinedData$recTime <- runif(nPatients, min = 0, max = recTime)
  
  combinedData$psuedoTime <- combinedData$time + combinedData$recTime
  
  censTime <- sort(combinedData$psuedoTime)[nEvents*0.5]
  
  combinedData$status <- combinedData$psuedoTime <= censTime
  
  combinedData$status <- combinedData$status*1
  
  combinedData$enrolled <- combinedData$recTime <= censTime
  
  combinedData <-  combinedData[combinedData$enrolled==T,]
  
  combinedData$survival_time <- ifelse(combinedData$psuedoTime>censTime, censTime  - combinedData$recTime, combinedData$time)
  
  n <- sum(combinedData$group=="Control")
  m <- nrow(combinedData)
  
  combinedData <- combinedData[order(combinedData$group),]
  
 

  #We need to update the priors using this interim data
  modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1, 1)T(0,)
    HR ~ dnorm(0.75, 1/HRsd)T(0,)
    bigT ~ dnorm(3, 1/bigTsd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = combinedData$survival_time, datEvent = combinedData$status, bigTsd = 1, HRsd = 0.1, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT", "lambda2"), n.iter = 500)
  
plot(output)

 kmfit <- survfit(Surv(survival_time, status)~group, data = combinedData) 
  
  plot(kmfit, col = c("blue", "red"), xlim=c(0,50))
  
  cPatientsLeft <- (nPatients/2) - sum(combinedData$group=="Control") 
  
  tPatientsLeft <- (nPatients/2) - sum(combinedData$group=="Treatment") 
  
  BPPVec <- rep(NA, 1000)
  
  for (i in 1:1000){
    
  
  unenrolledRecTimes <- runif(cPatientsLeft+tPatientsLeft, censTime, recTime)
  
  HRoutput <- as.numeric(unlist(output[,1]))
  bigToutput <- as.numeric(unlist(output[,2]))
  lambda2output <- as.numeric(unlist(output[,3]))
  
  sampledHR <- sample(HRoutput, 1)
  sampledbigT <- sample(bigToutput, 1)
  sampledlambda2 <- sample(lambda2output, 1)
  sampledlambda1 <- sampledlambda2*sampledHR
  
  CP <- exp(-(sampledlambda2*sampledbigT))
  u <- runif(tPatientsLeft)

unenrolledData <- data.frame(time = c(rexp(cPatientsLeft, rate = sampledlambda2), ifelse(u>CP, (-log(u))/sampledlambda2, (1/sampledlambda1)*(sampledbigT*sampledlambda1-log(u)-sampledbigT*sampledlambda2))), group = c(rep("Control", cPatientsLeft),
                             rep("Treatment", tPatientsLeft)), recTime = unenrolledRecTimes)

unenrolledData$psuedoTime <- unenrolledData$time + unenrolledData$recTime

  
censoredData <- combinedData[combinedData$status==0,]

cCensored <- sum(censoredData$group=="Control")
tCensored <- sum(censoredData$group=="Treatment")

cCensoredData <- censoredData %>%
  filter(group=="Control")

cIASurv <- rexp(cCensored, rate = sampledlambda2)

censoredObs <- data.frame(time = cCensoredData$time+rexp(cCensored, rate = sampledlambda2), group = rep("Control", cCensored), recTime = cCensoredData$recTime)

censoredObs$psuedoTime <- censoredObs$time + censoredObs$recTime

tBeforeDelay <- censoredData %>%
  filter(group=="Treatment") %>%
  filter(survival_time < sampledbigT)

tAfterDelay <- censoredData %>%
  filter(group=="Treatment") %>%
  filter(survival_time > sampledbigT)

tBeforeDelay$IASurv <- tBeforeDelay$survival_time + rexp(nrow(tBeforeDelay), rate = sampledlambda2)

tBeforeDelay1 <- tBeforeDelay %>%
  filter(IASurv < sampledbigT)

tBeforeDelay2 <- tBeforeDelay %>%
  filter(IASurv > sampledbigT)

tBeforeDelay2$IASurv2 <- sampledbigT + rexp(nrow(tBeforeDelay2), rate = sampledlambda1)

tAfterDelay$IASurv <- tAfterDelay$survival_time + rexp(nrow(tAfterDelay), rate = sampledlambda1)

tBeforeDelay1$IApsuedoTime <- tBeforeDelay1$IASurv + tBeforeDelay1$recTime

tBeforeDelay2$IApsuedoTime <- tBeforeDelay2$IASurv2 + tBeforeDelay2$recTime

tAfterDelay$IApsuedoTime <- tAfterDelay$IASurv + tAfterDelay$recTime

tBeforeDelay1 <- tBeforeDelay1[,c(2:3, 8:9)]

tBeforeDelay2 <- tBeforeDelay2[,c(2:3, 9:10)]

tAfterDelay <- tAfterDelay[,c(2:3, 8:9)]

colnames(tBeforeDelay1) <- c("group", "recTime", "time", "psuedoTime")

colnames(tBeforeDelay2) <- c("group", "recTime", "time", "psuedoTime")

colnames(tAfterDelay) <- c("group", "recTime", "time", "psuedoTime")


finalDataset <- combinedData %>%
  filter(status==1)

finalDataset <- finalDataset[,1:4]

finalDataset <- rbind(finalDataset, tBeforeDelay1)

finalDataset <- rbind(finalDataset, tBeforeDelay2)

finalDataset <- rbind(finalDataset, tAfterDelay)

finalDataset <- rbind(finalDataset, unenrolledData)

finalDataset <- rbind(finalDataset, censoredObs)

censTime1 <- sort(finalDataset$psuedoTime)[nEvents]
  
  finalDataset$status <- finalDataset$psuedoTime <= censTime1
  
  finalDataset$status <- finalDataset$status*1
  
  finalDataset$enrolled <- finalDataset$recTime <= censTime1
  
  finalDataset <-  finalDataset[finalDataset$enrolled==T,]
  
  finalDataset$survival_time <- ifelse(finalDataset$psuedoTime>censTime1, censTime1  - finalDataset$recTime, finalDataset$time)
  
   test <- survdiff(Surv(survival_time, status)~group, data = finalDataset)
   
    # kmfit <- survfit(Surv(survival_time, status)~group, data = finalDataset) 
    # 
    #  plot(kmfit, col = c("blue", "red"), xlim=c(0,50))
    


   
   BPPVec[i] <- test$chisq > qchisq(0.95, 1)
   
  }
   



```






