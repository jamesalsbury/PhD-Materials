---
title: "futilityLook"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(truncnorm)
```

We are looking at including futility looks into the clinical trial. We recreate the results from [Korn and Freidlin (2018)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6366306/pdf/JCO.2018.77.7144.pdf). We have the following setup:
We require 512 events, a sample size of 680. We assume the hazard ratio is 0.75, we have uniform recruitment for 34 months. We have exponential survival in the control arm, with a median survival of 12 months. We introduce three futility rules:

1) Wieand rule
* At 50% information, stop if the observed HR > 1
* At 75% information, stop if the observed HR > 1

2) O'Brien-Fleming $\beta$ spending
* At 33% information, stop if the observed HR > 0.998
* At 67% information, stop if the observed HR > 0.913

3) Proposed rule - by Korn and Freidlin
* At 50% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1
* At 75% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1

```{r, echo=F}
futilityPowerFunc <- function(HR, lengthDelay){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

nSims <- 1e2
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  powervec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```
These are the results seen when HR is 0.75 and there is no delay

```{r, echo=F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 0))
```

These are the results seen when HR is 0.75 and there is a delay of 3 months

```{r, echo=F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 3))
```

These are the results seen when HR is 0.75 and there is a delay of 6 months

```{r, echo=F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 6))
```

These are the results seen when HR is 1 (and no delay)

```{r, echo=F}
knitr::kable(futilityPowerFunc(HR = 1, lengthDelay = 0))
```

These are the results seen when HR is 1.3 (and no delay)

```{r, echo=F}
knitr::kable(futilityPowerFunc(HR = 1.3, lengthDelay = 0))
```

# Assurance

We can add some uncertainty to the parameters to see if this makes a difference to the calculations shown for futility

```{r, echo=F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12


nSims <- 1e2
assvec <- rep(NA, nSims)
Wieandassvec <- rep(NA, nSims)
OBFassvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandassvec[i] <- 4
    } else {
      Wieandassvec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFassvec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFassvec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFassvec[i] <- 4
    } else {
      OBFassvec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Wieand = c(mean(Wieandassvec==4), mean(Wieandcensvec)), OBF = c(mean(OBFassvec==4), mean(OBFcensvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(0, 0^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 0, lengthDelaysd = 0))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.01^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.01, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(6, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 6, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(1, 0.001^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 1, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```



