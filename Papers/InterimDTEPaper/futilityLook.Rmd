---
title: "futilityLook"
output: html_document
date: "2023-03-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(truncnorm)
```

We are looking at including futility looks into the clinical trial. We recreate the results from [Korn and Freidlin (2018)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6366306/pdf/JCO.2018.77.7144.pdf). We have the following setup:
We require 512 events, a sample size of 680. We assume the hazard ratio is 0.75, we have uniform recruitment for 34 months. We have exponential survival in the control arm, with a median survival of 12 months. We introduce three futility rules:

1) Wieand rule
* At 50% information, stop if the observed HR > 1
* At 75% information, stop if the observed HR > 1

2) O'Brien-Fleming $\beta$ spending
* At 33% information, stop if the observed HR > 0.998
* At 67% information, stop if the observed HR > 0.913

3) Proposed rule - by Korn and Freidlin
* At 50% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1
* At 75% information (assuming that 2/3 observed events have occurred later than 3 months), stop if the observed HR > 1

```{r, echo=F, eval = F}
futilityPowerFunc <- function(HR, lengthDelay){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12
lambdat <- lambdac*HR

nSims <- 1e3
powervec <- rep(NA, nSims)
Wieandpowervec <- rep(NA, nSims)
OBFpowervec <- rep(NA, nSims)
proppowervec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  powervec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandpowervec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    Wieandcensvec[i] <- censTime
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandpowervec[i] <- 4
    } else {
      Wieandpowervec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFpowervec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFpowervec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFpowervec[i] <- 4
    } else {
      OBFpowervec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    proppowervec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    proppowervec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     proppowervec[i] <- 4
    } else {
     proppowervec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(powervec==1), mean(censvec)), Wieand = c(mean(Wieandpowervec==4), mean(Wieandcensvec)), OBF = c(mean(OBFpowervec==4), mean(OBFcensvec)), Proposed = c(mean(proppowervec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```
These are the results seen when HR is 0.75 and there is no delay

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 0))
```

These are the results seen when HR is 0.75 and there is a delay of 3 months

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 3))
```

These are the results seen when HR is 0.75 and there is a delay of 6 months

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 0.75, lengthDelay = 6))
```

These are the results seen when HR is 1 (and no delay)

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 1, lengthDelay = 0))
```

These are the results seen when HR is 1.3 (and no delay)

```{r, echo=F, eval = F}
knitr::kable(futilityPowerFunc(HR = 1.3, lengthDelay = 0))
```

# Assurance

We can add some uncertainty to the parameters to see if this makes a difference to the calculations shown for futility

```{r, echo=F, eval = F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 1e3
assvec <- rep(NA, nSims)
Wieandassvec <- rep(NA, nSims)
OBFassvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
Wieandcensvec <- rep(NA, nSims)
OBFcensvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  #Wieand rule
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 1
    Wieandcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    Wieandassvec[i] <- 2
    Wieandcensvec[i] <- IATime2
  } else {
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      Wieandassvec[i] <- 4
    } else {
      Wieandassvec[i] <- 3
    }
    
  }
  
  }
  
  #O'Brien-Fleming approach
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[nEvents*0.5,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.998){
    OBFassvec[i] <- 1
    OBFcensvec[i] <- IATime1
  } else {
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[nEvents*0.75,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>0.913){
    OBFassvec[i] <- 2
    OBFcensvec[i] <- IATime2
  } else {
    OBFcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
      OBFassvec[i] <- 4
    } else {
      OBFassvec[i] <- 3
    }
    
  }
  
  }
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Wieand = c(mean(Wieandassvec==4), mean(Wieandcensvec)), OBF = c(mean(OBFassvec==4), mean(OBFcensvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(0, 0^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 0, lengthDelaysd = 0))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.01^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.01, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(6, 0.01^2)$  

HR $\sim N(0.75, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.001, lengthDelayMean = 6, lengthDelaysd = 0.01))
```

We have the following distributions for T and HR:  

$T \sim N(3, 0.01^2)$  

HR $\sim N(1, 0.001^2)$

```{r, echo=F, eval = F}
knitr::kable(futilityAssFunc(HRMean = 1, HRsd = 0.001, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

# Doing the Bayesian updating at the interim

We need to find a way of updating the prior distributions at any interim analysis


```{r, eval = F}
library(rjags)

bigTsd <- 0.001

HRVec <- rep(NA, 100)

for (j in 1:100){
  HR <- rnorm(1, mean = 0.75, sd = 0.05)
bigT <- truncnorm::rtruncnorm(n = 1, a = 0, mean = 3, sd = bigTsd)
lambdac <- -log(0.5)/12
lambdat  <- lambdac*HR
nEvents <- 512
nPatients <- 680
recTime <- 34

CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]

  samplevec <- sample(1:nPatients)

  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #Look at a futility stop 50% the way through the events
  
  IAData <- combinedData
  
  IATime  <- IAData[nEvents*0.5,]$time
  
  IAData$status <- IAData$time<=IATime
  
  IAData[IAData$status==F,]$time <- IATime
  
  IAData <- IAData[order(IAData$group),]

  controlkm <- survfit(Surv(time, status)~group, data = IAData)
# 
#plot(controlkm, col=c("blue", "red"))

#legend("topright", legend = c("Control", "Treatment"), col = c("blue", "red"), lty=1)

 coxmodel <- coxph(Surv(time, status)~group, data = IAData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))

n <- nPatients/2
m <- nPatients

#JAGS code which calculates posterior distributions

modelstring="

data {
  for (j in 1:m){
    zeros[j] <- 0
  }
}

model {
  C <- 10000
  for (i in 1:n){
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, log(lambda2)-(lambda2*datTimes[i]), -(lambda2*datTimes[i]))
  }
  for (i in (n+1):m){                                                                                                             
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <-  -l[i] + C
    l[i] <- ifelse(datEvent[i]==1, ifelse(datTimes[i]<bigT, log(lambda2)-(lambda2*datTimes[i]), log(lambda1)-lambda1*(datTimes[i]-bigT)-(bigT*lambda2)), 
      ifelse(datTimes[i]<bigT, -(lambda2*datTimes[i]), -(lambda2*bigT)-lambda1*(datTimes[i]-bigT)))
  }
  
    lambda2 ~ dbeta(1, 1)T(0,)
    HR ~ dnorm(0.75, 40)T(0,)
    bigT ~ dnorm(3, 1/bigTsd^2)T(0,)
    lambda1 <- lambda2*HR
    
    }
"

model = jags.model(textConnection(modelstring), data = list(datTimes = IAData$time, datEvent = IAData$status, bigTsd = bigTsd, n= n, m=m), quiet = T) 
                   
                   
update(model, n.iter=100)
output=coda.samples(model=model, variable.names=c("HR", "bigT"), n.iter = 500)

HROutput <- as.numeric(output[[1]][,1])

HRVec[j] <- mean(HROutput<1)
}

hist(HRVec)

```

```{r, eval = F}

myFunc <- function(bigTsd){
  lambdac <- -log(0.5)/12
nEvents <- 512
nPatients <- 680
recTime <- 34
assvec <- rep(NA, 100)
sampledHR <- rep(NA, 100)
observedHR <- rep(NA, 100)

for (i in 1:length(assvec)){
  
  HR <- rnorm(1, mean = 0.75, sd = 0.05)
  sampledHR[i] <- HR
bigT <- truncnorm::rtruncnorm(n = 1, a = 0,  mean = 3, sd = bigTsd)
lambdat  <- lambdac*HR
  
  CP <- exp(-(lambdac*bigT))
u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(bigT*lambdat-log(u)-bigT*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]

  samplevec <- sample(1:nPatients)

  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  observedHR[i] <- as.numeric(exp(coef(coxmodel)))
  
  #Look at a futility stop 50% the way through the events
  
  IAData1 <- combinedData
  
  IATime1  <- IAData1[nEvents*0.5,]$time
  
  IAData1$status <- IAData1$time<=IATime1
  
  IAData1[IAData1$status==F,]$time <- IATime1
  
  IAData1 <- IAData1[order(IAData1$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IAData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    assvec[i] <- 1
  } else {
    
  IAData2 <- combinedData
  
  IATime2  <- IAData2[nEvents*0.75,]$time
  
  IAData2$status <- IAData2$time<=IATime2
  
  IAData2[IAData2$status==F,]$time <- IATime2
  
  IAData2 <- IAData1[order(IAData2$group),]
  
  coxmodel <- coxph(Surv(time, status)~group, data = IAData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    assvec[i] <- 2
  } else {
    
    test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (test$chisq>qchisq(0.95, 1)&deltad<1){
    assvec[i] <- 4
  } else{
    assvec[i] <- 3
  }
    
    
  }
  }
}
mydf <- data.frame(StopFirstLook = mean(assvec==1), StopSecondLook = mean(assvec==2),
                   NotSignifFinal = mean(assvec==3), SignifFinal = mean(assvec==4))

return(list(mydf = mydf, sampledHR = sampledHR, observedHR = observedHR))
}


```

```{r, eval = F}

output <- myFunc(1)

plot(output$sampledHR, output$observedHR, xlim=c(0.5, 1.2), ylim=c(0.5, 1.2))

# myFunc(0.5)
# 
# myFunc(1)
```

How does changing the prior for T affect the futility/power?

```{r, echo=F}

futilityAssFunc <- function(HRMean, HRsd, lengthDelayMean, lengthDelaysd){
nEvents <- 512
nPatients <- 680
recTime <- 34
lambdac <- -log(0.5)/12

nSims <- 1e3
assvec <- rep(NA, nSims)
propassvec <- rep(NA, nSims)

censvec <- rep(NA, nSims)
propcensvec <- rep(NA, nSims)

for (i in 1:nSims){
  
  HR <- truncnorm::rtruncnorm(1, a = 0, mean = HRMean, sd = HRsd)
  lengthDelay <- truncnorm::rtruncnorm(1, a = -1e-10, mean = lengthDelayMean, sd = lengthDelaysd)
  lambdat <- lambdac*HR
  
  CP <- exp(-(lambdac*lengthDelay))
  u <- runif(nPatients/2)
  
  combinedData <- data.frame(time = c(rexp(nPatients/2, rate = lambdac), ifelse(u>CP, (-log(u))/lambdac, (1/lambdat)*(lengthDelay*lambdat-log(u)-lengthDelay*lambdac))), group = c(rep("Control", nPatients/2),
                             rep("Treatment", nPatients/2)))
  
  combinedData <- combinedData[order(combinedData$time),]
  
  samplevec <- sample(1:nPatients)
  
  for (k in 1:nPatients){
    combinedData[samplevec[k],]$time <- combinedData[samplevec[k],]$time + runif(1, min = floor(k/20), max = ceiling(k/20))
  }
  
 
  combinedData <- combinedData[order(combinedData$time),]
  
  censTime <- combinedData[nEvents,]$time
  
  censvec[i] <- censTime
  
  combinedData$status <- combinedData$time<=censTime
  
  combinedData[combinedData$status==F,]$time <- censTime
  
  #No interim analysis
  
  test <- survdiff(Surv(time, status)~group, data = combinedData)
  
  coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  assvec[i] <- (test$chisq > qchisq(0.95, 1) & deltad<1)
  
  
   #Proposed approach
  
  
  propvec <- rep(NA, nrow(combinedData))
  
  lessthan3 <- sum(combinedData$time<3)
  
  for (j in 1:nrow(combinedData)){
    if (combinedData$time[j]<3){
      propvec[j] <- 0
    } else {
      propvec[j] <- 1 - lessthan3/j
    }
  }
   
  thresholdEvent <- sum(propvec<(2/3))
  
  firstIAEvent <- max(thresholdEvent, nEvents*0.5)
  
  IACombinedData1 <- combinedData
  
  IATime1 <- IACombinedData1[firstIAEvent,]$time
  
  IACombinedData1$status <- IACombinedData1$time<=IATime1
  
  IACombinedData1[IACombinedData1$status==F,]$time <- IATime1
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData1)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime1
    propassvec[i] <- 1
  } else {
  
  secondIAEvent <- max(thresholdEvent, nEvents*0.75)    
    
  IACombinedData2 <- combinedData
  
  IATime2 <- IACombinedData2[secondIAEvent,]$time
  
  IACombinedData2$status <- IACombinedData2$time<=IATime2
  
  IACombinedData2[IACombinedData2$status==F,]$time <- IATime2
  
  coxmodel <- coxph(Surv(time, status)~group, data = IACombinedData2)
  
  deltad <- as.numeric(exp(coef(coxmodel)))
  
  if (deltad>1){
    propcensvec[i] <- IATime2
    propassvec[i] <- 2
  } else {
    propcensvec[i] <- censTime
    coxmodel <- coxph(Surv(time, status)~group, data = combinedData)
  deltad <- as.numeric(exp(coef(coxmodel)))
    if (test$chisq > qchisq(0.95, 1)&deltad<1){
     propassvec[i] <- 4
    } else {
     propassvec[i] <- 3
    }
  }
  }
}

simResults <- data.frame(No.interim = c(mean(assvec==1), mean(censvec)), Proposed = c(mean(propassvec==4), mean(propcensvec)))

rownames(simResults) <- c("Power", "Mean time")

return(simResults)
}


```


We have the following distributions for T and HR:  

$T \sim N(3, 0^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0))
```


$T \sim N(3, 0.0001^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.0001))
```

$T \sim N(3, 0.001^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.001))
```

$T \sim N(3, 0.01^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.01))
```

$T \sim N(3, 0.1^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 0.1))
```

$T \sim N(3, 1^2)$  

HR $\sim N(0.75, 0.1^2)$

```{r, echo=F}
knitr::kable(futilityAssFunc(HRMean = 0.75, HRsd = 0.1, lengthDelayMean = 3, lengthDelaysd = 1))
```
